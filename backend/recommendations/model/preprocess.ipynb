{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_datalist = []\n",
    "with open('../data/photos.json', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        photo_datalist.append(data)\n",
    "\n",
    "restaurant_datalist = []\n",
    "with open('../data/yelp_academic_dataset_business.json', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        restaurant_datalist.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                             {'ByAppointmentOnly': 'True'}\n",
      "1                    {'BusinessAcceptsCreditCards': 'True'}\n",
      "2         {'BikeParking': 'True', 'BusinessAcceptsCredit...\n",
      "3         {'RestaurantsDelivery': 'False', 'OutdoorSeati...\n",
      "4         {'BusinessAcceptsCreditCards': 'True', 'Wheelc...\n",
      "                                ...                        \n",
      "150341    {'ByAppointmentOnly': 'False', 'RestaurantsPri...\n",
      "150342    {'BusinessAcceptsCreditCards': 'True', 'Restau...\n",
      "150343    {'RestaurantsPriceRange2': '1', 'BusinessAccep...\n",
      "150344    {'BusinessParking': '{'garage': False, 'street...\n",
      "150345    {'WheelchairAccessible': 'True', 'BusinessAcce...\n",
      "Name: attributes, Length: 150346, dtype: object\n",
      "Index(['Name', 'Address', 'Location', 'Price', 'Cuisine', 'Longitude',\n",
      "       'Latitude', 'PhoneNumber', 'Url', 'WebsiteUrl', 'Award', 'GreenStar',\n",
      "       'FacilitiesAndServices', 'Description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# clean photos\n",
    "# create dataframe\n",
    "picture_df = pd.DataFrame(photo_datalist)\n",
    "restaurant_df = pd.DataFrame(restaurant_datalist)\n",
    "michelin_df = pd.read_csv('../data/michelin.csv')\n",
    "print(restaurant_df['attributes'])\n",
    "print(michelin_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                      name  \\\n",
      "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
      "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
      "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
      "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
      "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
      "\n",
      "                           address           city state postal_code  \\\n",
      "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
      "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
      "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
      "3                      935 Race St   Philadelphia    PA       19107   \n",
      "4                    101 Walnut St     Green Lane    PA       18054   \n",
      "\n",
      "    latitude   longitude  stars  review_count  is_open  \\\n",
      "0  34.426679 -119.711197    5.0           7.0      0.0   \n",
      "1  38.551126  -90.335695    3.0          15.0      1.0   \n",
      "2  32.223236 -110.880452    3.5          22.0      0.0   \n",
      "3  39.955505  -75.155564    4.0          80.0      1.0   \n",
      "4  40.338183  -75.471659    4.5          13.0      1.0   \n",
      "\n",
      "                                          attributes  \\\n",
      "0                      {'ByAppointmentOnly': 'True'}   \n",
      "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
      "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
      "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
      "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
      "\n",
      "                                          categories  \\\n",
      "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
      "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
      "2  Department Stores, Shopping, Fashion, Home & G...   \n",
      "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
      "4                          Brewpubs, Breweries, Food   \n",
      "\n",
      "                                               hours  is_michelin  \\\n",
      "0                                               None        False   \n",
      "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...        False   \n",
      "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...        False   \n",
      "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...        False   \n",
      "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...        False   \n",
      "\n",
      "  RestaurantsPriceRange2  \n",
      "0                    NaN  \n",
      "1                    NaN  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4                    NaN  \n"
     ]
    }
   ],
   "source": [
    "# clean michelin\n",
    "michelin_df = michelin_df.drop(columns=['PhoneNumber', 'Url', 'WebsiteUrl', 'Award', 'GreenStar',\n",
    "       'FacilitiesAndServices', 'Description', 'Location'])\n",
    "# encode prices based on number of characters\n",
    "michelin_df[\"Price\"] = michelin_df[\"Price\"].apply(lambda x: str(len(str(x))))\n",
    "michelin_df = michelin_df.rename(columns={\"Price\": \"RestaurantsPriceRange2\", \"Name\": \"name\", \"City\": \"city\", \"Zip\": \"postal_code\", \"Latitude\": \"latitude\", \"Longitude\": \"longitude\", \"Cuisine\": \"categories\", \"Address\": \"address\"})\n",
    "# add price range information\n",
    "michelin_df[\"attributes\"] = michelin_df[\"RestaurantsPriceRange2\"].apply(lambda x: {\"RestaurantsPriceRange2\": x})\n",
    "michelin_df['is_michelin'] = True\n",
    "restaurant_df['is_michelin'] = False\n",
    "# generate random high ratings for michelin restaurants\n",
    "michelin_df['stars'] = np.random.uniform(4, 5, michelin_df.shape[0])\n",
    "# generate business_ids for michelin\n",
    "michelin_df['business_id'] = np.arange(len(michelin_df))\n",
    "# union michelin and restaurant\n",
    "restaurant_df = restaurant_df.rename(columns={\"name\": \"name\", \"city\": \"city\", \"postal_code\": \"postal_code\", \"latitude\": \"latitude\", \"longitude\": \"longitude\", \"price\": \"price\", \"categories\": \"categories\", \"address\": \"address\"})\n",
    "# merge michelin and restaurant\n",
    "restaurant_df = pd.concat([restaurant_df, michelin_df])\n",
    "print(restaurant_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def clean_and_encode_restaurant_attributes(df):\n",
    "    \"\"\"\n",
    "    Clean and encode restaurant attributes for a recommendation model.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing business data with 'attributes' column\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with cleaned and encoded attributes\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Step 1: Parse the attributes column if it's a string and not None\n",
    "    def parse_attributes(attr):\n",
    "        if attr is None:\n",
    "            return None\n",
    "        if isinstance(attr, str):\n",
    "            try:\n",
    "                # Handle single quotes used in JSON\n",
    "                attr = attr.replace(\"'\", '\"')\n",
    "                # Handle cases where string starts with u\n",
    "                attr = attr.replace('u\"', '\"')\n",
    "                return json.loads(attr)\n",
    "            except json.JSONDecodeError:\n",
    "                try:\n",
    "                    # Alternative parsing with ast.literal_eval\n",
    "                    return ast.literal_eval(attr)\n",
    "                except:\n",
    "                    return None\n",
    "        return attr\n",
    "    \n",
    "    # Apply parsing to the attributes column\n",
    "    df_clean['attributes'] = df_clean['attributes'].apply(parse_attributes)\n",
    "    \n",
    "    # Step 2: Filter out non-restaurants\n",
    "    # We'll consider a business a restaurant if it has any of the restaurant-specific attributes\n",
    "    restaurant_attrs = ['RestaurantsPriceRange2', 'RestaurantsAttire', 'NoiseLevel', \n",
    "                       'RestaurantsGoodForGroups', 'Alcohol', 'RestaurantsReservations']\n",
    "    \n",
    "    def is_restaurant(attr):\n",
    "        if attr is None:\n",
    "            return False\n",
    "        for rest_attr in restaurant_attrs:\n",
    "            if rest_attr in attr:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # Filter businesses that have at least one restaurant attribute\n",
    "    df_clean = df_clean[df_clean['attributes'].apply(is_restaurant)]\n",
    "    \n",
    "    # Step 3: Extract and encode each specific attribute\n",
    "    \n",
    "    # 3.1: RestaurantsPriceRange2 (numeric 1-4)\n",
    "    def extract_price_range(attr):\n",
    "        if attr is None or 'RestaurantsPriceRange2' not in attr:\n",
    "            return np.nan\n",
    "        try:\n",
    "            value = attr['RestaurantsPriceRange2']\n",
    "            if isinstance(value, str) and value.isdigit():\n",
    "                return int(value)\n",
    "            return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    df_clean['price_range'] = df_clean['attributes'].apply(extract_price_range)\n",
    "    \n",
    "    # 3.2: RestaurantsAttire (casual, dressy, formal)\n",
    "    def extract_attire(attr):\n",
    "        if attr is None or 'RestaurantsAttire' not in attr:\n",
    "            return 'unknown'\n",
    "        try:\n",
    "            value = attr['RestaurantsAttire']\n",
    "            # Clean up the string\n",
    "            value = value.lower().replace(\"'\", \"\").replace(\"u\", \"\").replace('\"', '')\n",
    "            return value\n",
    "        except:\n",
    "            return 'unknown'\n",
    "    \n",
    "    df_clean['attire'] = df_clean['attributes'].apply(extract_attire)\n",
    "    \n",
    "    # One-hot encode attire\n",
    "    attire_dummies = pd.get_dummies(df_clean['attire'], prefix='attire')\n",
    "    df_clean = pd.concat([df_clean, attire_dummies], axis=1)\n",
    "    \n",
    "    # 3.3: NoiseLevel (quiet, average, loud, very_loud)\n",
    "    def extract_noise_level(attr):\n",
    "        if attr is None or 'NoiseLevel' not in attr:\n",
    "            return 'unknown'\n",
    "        try:\n",
    "            value = attr['NoiseLevel']\n",
    "            # Clean up the string\n",
    "            value = value.lower().replace(\"'\", \"\").replace(\"u\", \"\").replace('\"', '')\n",
    "            return value\n",
    "        except:\n",
    "            return 'unknown'\n",
    "    \n",
    "    df_clean['noise_level'] = df_clean['attributes'].apply(extract_noise_level)\n",
    "    \n",
    "    # One-hot encode noise level\n",
    "    noise_dummies = pd.get_dummies(df_clean['noise_level'], prefix='noise')\n",
    "    df_clean = pd.concat([df_clean, noise_dummies], axis=1)\n",
    "    \n",
    "    # 3.4: RestaurantsGoodForGroups (boolean)\n",
    "    def extract_good_for_groups(attr):\n",
    "        if attr is None or 'RestaurantsGoodForGroups' not in attr:\n",
    "            return np.nan\n",
    "        try:\n",
    "            value = attr['RestaurantsGoodForGroups']\n",
    "            if isinstance(value, bool):\n",
    "                return 1 if value else 0\n",
    "            if isinstance(value, str):\n",
    "                return 1 if value.lower() == 'true' else 0\n",
    "            return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    df_clean['good_for_groups'] = df_clean['attributes'].apply(extract_good_for_groups)\n",
    "    \n",
    "    # 3.5: Alcohol (none, beer_and_wine, full_bar)\n",
    "    def extract_alcohol(attr):\n",
    "        if attr is None or 'Alcohol' not in attr:\n",
    "            return 'unknown'\n",
    "        try:\n",
    "            value = attr['Alcohol']\n",
    "            # Clean up the string\n",
    "            value = value.lower().replace(\"'\", \"\").replace(\"u\", \"\").replace('\"', '')\n",
    "            return value\n",
    "        except:\n",
    "            return 'unknown'\n",
    "    \n",
    "    df_clean['alcohol'] = df_clean['attributes'].apply(extract_alcohol)\n",
    "    \n",
    "    # One-hot encode alcohol\n",
    "    alcohol_dummies = pd.get_dummies(df_clean['alcohol'], prefix='alcohol')\n",
    "    df_clean = pd.concat([df_clean, alcohol_dummies], axis=1)\n",
    "    \n",
    "    # 3.6: RestaurantsReservations (boolean)\n",
    "    def extract_reservations(attr):\n",
    "        if attr is None or 'RestaurantsReservations' not in attr:\n",
    "            return np.nan\n",
    "        try:\n",
    "            value = attr['RestaurantsReservations']\n",
    "            if isinstance(value, bool):\n",
    "                return 1 if value else 0\n",
    "            if isinstance(value, str):\n",
    "                return 1 if value.lower() == 'true' else 0\n",
    "            return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    df_clean['takes_reservations'] = df_clean['attributes'].apply(extract_reservations)\n",
    "    \n",
    "    # 3.7: Ambience (dictionary with multiple boolean values)\n",
    "    # For Ambience, we'll extract common ambience attributes\n",
    "    ambience_attributes = ['romantic', 'intimate', 'touristy', 'hipster', 'divey', \n",
    "                          'classy', 'trendy', 'upscale', 'casual']\n",
    "    \n",
    "    def extract_ambience(attr, amb_attr):\n",
    "        if attr is None or 'Ambience' not in attr:\n",
    "            return np.nan\n",
    "        try:\n",
    "            ambience = attr['Ambience']\n",
    "            \n",
    "            # Handle the case where Ambience is a string representation of a dictionary\n",
    "            if isinstance(ambience, str):\n",
    "                if ambience.lower() == 'none':\n",
    "                    return np.nan\n",
    "                try:\n",
    "                    # Try to parse the string as a dictionary\n",
    "                    ambience = ambience.replace(\"'\", '\"')\n",
    "                    ambience = json.loads(ambience)\n",
    "                except:\n",
    "                    try:\n",
    "                        ambience = ast.literal_eval(ambience)\n",
    "                    except:\n",
    "                        return np.nan\n",
    "            \n",
    "            # Now extract the specific ambience attribute\n",
    "            if amb_attr in ambience:\n",
    "                value = ambience[amb_attr]\n",
    "                if value is None:\n",
    "                    return np.nan\n",
    "                if isinstance(value, bool):\n",
    "                    return 1 if value else 0\n",
    "                if isinstance(value, str):\n",
    "                    return 1 if value.lower() == 'true' else 0\n",
    "            return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Add columns for each ambience attribute\n",
    "    for amb_attr in ambience_attributes:\n",
    "        df_clean[f'ambience_{amb_attr}'] = df_clean['attributes'].apply(\n",
    "            lambda x: extract_ambience(x, amb_attr))\n",
    "    \n",
    "    # Fill NaN values with appropriate defaults\n",
    "    df_clean['price_range'] = df_clean['price_range'].fillna(df_clean['price_range'].mode()[0])\n",
    "    df_clean['good_for_groups'] = df_clean['good_for_groups'].fillna(0)\n",
    "    df_clean['takes_reservations'] = df_clean['takes_reservations'].fillna(0)\n",
    "    \n",
    "    # Fill NaN values in ambience columns\n",
    "    for amb_attr in ambience_attributes:\n",
    "        df_clean[f'ambience_{amb_attr}'] = df_clean[f'ambience_{amb_attr}'].fillna(0)\n",
    "    \n",
    "    # Drop the original attributes column and intermediate columns\n",
    "    columns_to_drop = ['attributes', 'attire', 'noise_level', 'alcohol']\n",
    "    df_clean = df_clean.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
      "       'categories', 'hours', 'is_michelin', 'RestaurantsPriceRange2',\n",
      "       'price_range', 'attire_casal', 'attire_dressy', 'attire_formal',\n",
      "       'attire_none', 'attire_unknown', 'noise_average', 'noise_lod',\n",
      "       'noise_none', 'noise_qiet', 'noise_unknown', 'noise_very_lod',\n",
      "       'good_for_groups', 'alcohol_beer_and_wine', 'alcohol_fll_bar',\n",
      "       'alcohol_none', 'alcohol_unknown', 'takes_reservations',\n",
      "       'ambience_romantic', 'ambience_intimate', 'ambience_touristy',\n",
      "       'ambience_hipster', 'ambience_divey', 'ambience_classy',\n",
      "       'ambience_trendy', 'ambience_upscale', 'ambience_casual'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "restaurant_df = clean_and_encode_restaurant_attributes(restaurant_df)\n",
    "print(restaurant_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of food establishments: 42949\n",
      "Number of photos for food establishments: 45207\n",
      "\n",
      "Sample categories in filtered dataset:\n",
      "2766                      Modern Cuisine, Seasonal Cuisine\n",
      "14027                                   Smørrebrød, Danish\n",
      "17588                             Creative, Modern Cuisine\n",
      "6694     Food, Do-It-Yourself Food, Breakfast & Brunch,...\n",
      "13093                                              Italian\n",
      "Name: categories, dtype: object\n",
      "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
      "       'categories', 'hours', 'is_michelin', 'RestaurantsPriceRange2',\n",
      "       'price_range', 'attire_casal', 'attire_dressy', 'attire_formal',\n",
      "       'attire_none', 'attire_unknown', 'noise_average', 'noise_lod',\n",
      "       'noise_none', 'noise_qiet', 'noise_unknown', 'noise_very_lod',\n",
      "       'good_for_groups', 'alcohol_beer_and_wine', 'alcohol_fll_bar',\n",
      "       'alcohol_none', 'alcohol_unknown', 'takes_reservations',\n",
      "       'ambience_romantic', 'ambience_intimate', 'ambience_touristy',\n",
      "       'ambience_hipster', 'ambience_divey', 'ambience_classy',\n",
      "       'ambience_trendy', 'ambience_upscale', 'ambience_casual'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# # NEW: Exclude additional non-food related businesses\n",
    "non_food_terms = '|'.join(['Salon', 'Barber', 'Gym', 'Spa', 'Theater', 'Nightlife', 'Beauty', 'Barbershop', \"Active Life\",\n",
    "    \"Automotive\",\n",
    "    \"Beauty & Spas\",\n",
    "    \"Home Services\",\n",
    "    \"Health & Medical\",\n",
    "    \"Hotels & Travel\",\n",
    "    \"Local Services\",\n",
    "    \"Professional Services\",\n",
    "    \"Public Services & Government\",\n",
    "    \"Real Estate\",\n",
    "    \"Religious Organizations\",\n",
    "    \"Shopping & Retail\",\n",
    "    \"Transportation\",\n",
    "    \"Arts & Entertainment\",\n",
    "    \"Event Planning & Services\",\n",
    "    \"Education\",\n",
    "    \"Financial Services\",\n",
    "    \"Nightlife\",\n",
    "    \"Pets & Animal Services\",\n",
    "    \"Sports & Recreation\",\n",
    "    \"Miscellaneous Services\"\n",
    "])\n",
    "# Apply filter only to non-Michelin restaurants\n",
    "non_michelin_mask = ~restaurant_df['is_michelin']\n",
    "food_mask = restaurant_df['categories'].str.contains('Food', case=False, na=False)\n",
    "non_food_mask = restaurant_df['categories'].str.contains(non_food_terms, case=False, na=False)\n",
    "\n",
    "# Keep all Michelin restaurants and apply filter to non-Michelin ones\n",
    "restaurant_df = restaurant_df[\n",
    "    restaurant_df['is_michelin'] | \n",
    "    (non_michelin_mask & food_mask & ~non_food_mask)\n",
    "]\n",
    "picture_df = picture_df[picture_df['label'] != 'inside']\n",
    "picture_df = picture_df[picture_df['label'] != 'outside']\n",
    "picture_df = picture_df[picture_df['label'] != 'menu']\n",
    "\n",
    "# Keep only photos that belong to the filtered restaurants\n",
    "picture_df = picture_df[picture_df['business_id'].isin(restaurant_df['business_id'])]\n",
    "\n",
    "# Print statistics\n",
    "print(\"Number of food establishments:\", len(restaurant_df))\n",
    "print(\"Number of photos for food establishments:\", len(picture_df))\n",
    "print(\"\\nSample categories in filtered dataset:\")\n",
    "print(restaurant_df['categories'].sample(5))\n",
    "print(restaurant_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "Total pictures: 45207\n",
      "Pictures with valid restaurant links: 45207\n",
      "Pictures with invalid restaurant links: 0\n",
      "\n",
      "All pictures are linked to valid restaurants!\n"
     ]
    }
   ],
   "source": [
    "# New cell for validation\n",
    "# Check if all pictures link to valid restaurants\n",
    "# get business_ids of non-michelin restaurants\n",
    "valid_business_ids = set(restaurant_df[~restaurant_df['is_michelin']]['business_id'])\n",
    "invalid_pictures = picture_df[~picture_df['business_id'].isin(valid_business_ids)]\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(f\"Total pictures: {len(picture_df)}\")\n",
    "print(f\"Pictures with valid restaurant links: {len(picture_df) - len(invalid_pictures)}\")\n",
    "print(f\"Pictures with invalid restaurant links: {len(invalid_pictures)}\")\n",
    "\n",
    "if len(invalid_pictures) > 0:\n",
    "    print(\"\\nSample of invalid picture entries:\")\n",
    "    print(invalid_pictures.head())\n",
    "else:\n",
    "    print(\"\\nAll pictures are linked to valid restaurants!\")\n",
    "\n",
    "# Optional: Remove any invalid pictures if found\n",
    "if len(invalid_pictures) > 0:\n",
    "    picture_df = picture_df[picture_df['business_id'].isin(valid_business_ids)]\n",
    "    print(f\"\\nCleaned dataset now contains {len(picture_df)} valid pictures\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categories column as binary features and update the restaurant dataframe\n",
    "# keep business_id, latitude, longitude, stars, and category columns for use in the recommender system\n",
    "categories = restaurant_df['categories'].str.get_dummies(sep=', ').replace({np.nan: 0})\n",
    "restaurant_df = pd.concat([restaurant_df, categories], axis=1)\n",
    "restaurant_df.drop(columns=['categories', 'hours'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count',\n",
      "       ...\n",
      "       'World Cuisine', 'Wraps', 'Xibei', 'Xinjiang', 'Yakitori',\n",
      "       'Yelp Events', 'Yoshoku', 'Yukhoe', 'Yunnanese', 'Zhejiang'],\n",
      "      dtype='object', length=562)\n",
      "               business_id                   name              address  \\\n",
      "3   MTSW4McQd7CbVtyjqoe9mw     St Honore Pastries          935 Race St   \n",
      "5   CF33F8-E6oudUQ46HnavjQ         Sonic Drive-In        615 S Main St   \n",
      "9   bBDDEgkFA1Otx9Lfe7BZUQ         Sonic Drive-In  2312 Dickerson Pike   \n",
      "11  eEOYSgkmpB90uNA7lDOMRA  Vietnamese Food Truck                        \n",
      "14  0bPLkL0QhhPO5kt1_EXmNQ   Zio's Italian Market        2575 E Bay Dr   \n",
      "\n",
      "            city state postal_code   latitude  longitude  stars  review_count  \\\n",
      "3   Philadelphia    PA       19107  39.955505 -75.155564    4.0          80.0   \n",
      "5   Ashland City    TN       37015  36.269593 -87.058943    2.0           6.0   \n",
      "9      Nashville    TN       37207  36.208102 -86.768170    1.5          10.0   \n",
      "11     Tampa Bay    FL       33602  27.955269 -82.456320    4.0          10.0   \n",
      "14         Largo    FL       33771  27.916116 -82.760461    4.5         100.0   \n",
      "\n",
      "    ...  World Cuisine  Wraps Xibei  Xinjiang  Yakitori  Yelp Events  Yoshoku  \\\n",
      "3   ...              0      0     0         0         0            0        0   \n",
      "5   ...              0      0     0         0         0            0        0   \n",
      "9   ...              0      0     0         0         0            0        0   \n",
      "11  ...              0      0     0         0         0            0        0   \n",
      "14  ...              0      0     0         0         0            0        0   \n",
      "\n",
      "    Yukhoe  Yunnanese  Zhejiang  \n",
      "3        0          0         0  \n",
      "5        0          0         0  \n",
      "9        0          0         0  \n",
      "11       0          0         0  \n",
      "14       0          0         0  \n",
      "\n",
      "[5 rows x 562 columns]\n",
      "(42949, 562)\n"
     ]
    }
   ],
   "source": [
    "print(restaurant_df.columns)\n",
    "print(restaurant_df.head(5))\n",
    "print(restaurant_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values before saving the dataset:\n",
      "RestaurantsPriceRange2    25203\n",
      "city                      17746\n",
      "state                     17746\n",
      "postal_code               17746\n",
      "review_count              17746\n",
      "is_open                   17746\n",
      "business_id                   0\n",
      "Noodles and Congee            0\n",
      "Naengmyeon                    0\n",
      "Nakagyo-ku                    0\n",
      "dtype: int64\n",
      "\n",
      "Handling 539 numeric columns and 23 non-numeric columns\n",
      "\n",
      "Remaining NaN values after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# New cell to handle NaN values before saving\n",
    "print(\"Checking for NaN values before saving the dataset:\")\n",
    "print(restaurant_df.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# Identify numeric columns for appropriate filling\n",
    "numeric_cols = restaurant_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric_cols = restaurant_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nHandling {len(numeric_cols)} numeric columns and {len(non_numeric_cols)} non-numeric columns\")\n",
    "\n",
    "# Fill numeric columns with 0 (could also use mean/median if appropriate)\n",
    "restaurant_df[numeric_cols] = restaurant_df[numeric_cols].fillna(0)\n",
    "\n",
    "# Fill non-numeric columns with empty string\n",
    "restaurant_df[non_numeric_cols] = restaurant_df[non_numeric_cols].fillna('')\n",
    "\n",
    "# Final check to ensure no NaN values remain\n",
    "remaining_nans = restaurant_df.isna().sum().sum()\n",
    "print(f\"\\nRemaining NaN values after cleaning: {remaining_nans}\")\n",
    "if remaining_nans > 0:\n",
    "    print(\"Columns still containing NaNs:\")\n",
    "    print(restaurant_df.columns[restaurant_df.isna().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining photos in the folder: 40062\n"
     ]
    }
   ],
   "source": [
    "# parse photos folder and remove any photos that are not in the cleaned dataset\n",
    "import os\n",
    "\n",
    "# Create a set of valid photo IDs\n",
    "valid_photo_ids = set(picture_df['photo_id'])\n",
    "\n",
    "# Define the path to the photos folder\n",
    "photos_folder = '../data/photos'\n",
    "\n",
    "# Iterate over all files in the photos folder\n",
    "for filename in os.listdir(photos_folder):\n",
    "    # Extract the photo ID from the filename\n",
    "    photo_id = filename.split('.')[0]\n",
    "    \n",
    "    # Check if the photo ID is not in the valid set\n",
    "    if photo_id not in valid_photo_ids:\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(photos_folder, filename)\n",
    "        \n",
    "        # Remove the file\n",
    "        os.remove(file_path)\n",
    "        print(f\"Removed invalid photo: {filename}\")\n",
    "        \n",
    "# Check the number of photos in the folder\n",
    "print(f\"Remaining photos in the folder: {len(os.listdir(photos_folder))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing dimensionality reduction by removing sparse columns...\n",
      "Found 432 sparse columns with more than 99.5% zeros\n",
      "\n",
      "Dimensionality reduction complete:\n",
      "- Before: 562 columns\n",
      "- After: 130 columns\n",
      "- Removed: 432 sparse columns (76.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "print(\"Implementing dimensionality reduction by removing sparse columns...\")\n",
    "\n",
    "binary_cols = restaurant_df.columns[(restaurant_df.isin([0, 1]).sum() == len(restaurant_df))]\n",
    "sparsity = 1.0 - (restaurant_df[binary_cols].astype(bool).sum() / len(restaurant_df))\n",
    "\n",
    "sparsity_threshold = 0.995  # 99.5% zeros (0.5% non-zeros)\n",
    "\n",
    "sparse_columns = sparsity[sparsity > sparsity_threshold].index.tolist()\n",
    "print(f\"Found {len(sparse_columns)} sparse columns with more than {sparsity_threshold*100:.1f}% zeros\")\n",
    "\n",
    "\n",
    "restaurant_df_before = restaurant_df.shape[1]\n",
    "restaurant_df = restaurant_df.drop(columns=sparse_columns)\n",
    "restaurant_df_after = restaurant_df.shape[1]\n",
    "\n",
    "print(f\"\\nDimensionality reduction complete:\")\n",
    "print(f\"- Before: {restaurant_df_before} columns\")\n",
    "print(f\"- After: {restaurant_df_after} columns\")\n",
    "print(f\"- Removed: {restaurant_df_before - restaurant_df_after} sparse columns ({(restaurant_df_before - restaurant_df_after) / restaurant_df_before * 100:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save restaurants to json for db import and csv for model training\n",
    "restaurant_df_model_training = restaurant_df.copy().drop(columns=['name', 'address', 'city', 'state', 'postal_code'])\n",
    "picture_df.to_csv('../data/cleaned_photos.csv', index=False)\n",
    "\n",
    "restaurant_df_database = restaurant_df.copy()\n",
    "picture_df.to_json('../data/cleaned_photos.json', orient='records', lines=True)\n",
    "\n",
    "restaurant_df_database.to_json('../data/cleaned_restaurants.json', orient='records', lines=True)\n",
    "restaurant_df_model_training.to_csv('../data/cleaned_restaurants.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
