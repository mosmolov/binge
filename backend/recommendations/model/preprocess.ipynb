{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "49871d49",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "5f1cee33",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "photo_datalist = []\n",
        "with open('../data/photos.json', 'r') as file:\n",
        "    for line in file:\n",
        "        data = json.loads(line)\n",
        "        photo_datalist.append(data)\n",
        "\n",
        "restaurant_datalist = []\n",
        "with open('../data/yelp_academic_dataset_business.json', 'r') as file:\n",
        "    for line in file:\n",
        "        data = json.loads(line)\n",
        "        restaurant_datalist.append(data)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "d75bf2e8",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                             {'ByAppointmentOnly': 'True'}\n",
            "1                    {'BusinessAcceptsCreditCards': 'True'}\n",
            "2         {'BikeParking': 'True', 'BusinessAcceptsCredit...\n",
            "3         {'RestaurantsDelivery': 'False', 'OutdoorSeati...\n",
            "4         {'BusinessAcceptsCreditCards': 'True', 'Wheelc...\n",
            "                                ...                        \n",
            "150341    {'ByAppointmentOnly': 'False', 'RestaurantsPri...\n",
            "150342    {'BusinessAcceptsCreditCards': 'True', 'Restau...\n",
            "150343    {'RestaurantsPriceRange2': '1', 'BusinessAccep...\n",
            "150344    {'BusinessParking': '{'garage': False, 'street...\n",
            "150345    {'WheelchairAccessible': 'True', 'BusinessAcce...\n",
            "Name: attributes, Length: 150346, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# clean photos\n",
        "# create dataframe\n",
        "picture_df = pd.DataFrame(photo_datalist)\n",
        "restaurant_df = pd.DataFrame(restaurant_datalist)\n",
        "michelin_df = pd.read_csv('../data/michelin.csv')\n",
        "print(restaurant_df['attributes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "7b0713e8",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# clean michelin\n",
        "michelin_df = michelin_df.drop(columns=['PhoneNumber', 'Url', 'WebsiteUrl', 'Award', 'GreenStar', 'Description', 'Location'])\n",
        "# encode prices based on number of characters\n",
        "michelin_df[\"Price\"] = michelin_df[\"Price\"].apply(lambda x: str(len(str(x))))\n",
        "facilities_and_services = michelin_df[\"FacilitiesAndServices\"].apply(lambda x: x.split(\",\") if isinstance(x, str) else [])\n",
        "michelin_df[\"attributes\"] = facilities_and_services.apply(lambda x: {item.strip(): True for item in x})\n",
        "# Process cuisine properly - use apply with a function that has access to row index\n",
        "for idx, row in michelin_df.iterrows():\n",
        "    cuisine_list = row[\"Cuisine\"].split(\",\") if isinstance(row[\"Cuisine\"], str) else []\n",
        "    cuisine_clean = [c.strip() for c in cuisine_list]\n",
        "    price = row[\"Price\"]\n",
        "    # Update attributes for this specific row\n",
        "    michelin_df.at[idx, \"attributes\"] = {**michelin_df.at[idx, \"attributes\"], \n",
        "                                         \"Cuisine\": cuisine_clean,\n",
        "                                         \"RestaurantsPriceRange2\": price.strip()}\n",
        "michelin_df['is_michelin'] = True\n",
        "restaurant_df['is_michelin'] = False\n",
        "# generate random high ratings for michelin restaurants\n",
        "michelin_df['stars'] = np.random.uniform(4, 5, michelin_df.shape[0])\n",
        "# generate business_ids for michelin\n",
        "michelin_df['business_id'] = np.arange(len(michelin_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "0dc98f59",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# align michelin_df and restaurant_df\n",
        "restaurant_df = restaurant_df.drop(columns=['hours', 'review_count', 'is_open'])\n",
        "michelin_df = michelin_df.drop(columns=['FacilitiesAndServices', 'Cuisine', 'Price'])\n",
        "michelin_df = michelin_df.rename(columns={\n",
        "    \"Name\": \"name\",\n",
        "    \"Address\": \"address\",\n",
        "    \"Longitude\": \"longitude\",\n",
        "    \"Latitude\": \"latitude\",\n",
        "})\n",
        "# combine address, city, state, postal_code fields into one column\n",
        "restaurant_df[\"address\"] = restaurant_df[\"address\"] + \", \" + restaurant_df[\"city\"] + \", \" + restaurant_df[\"state\"] + \" \" + restaurant_df[\"postal_code\"]\n",
        "restaurant_df = restaurant_df.drop(columns=['city', 'state', 'postal_code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "35a3316b",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of food establishments: 51036\n",
            "Number of photos for food establishments: 81941\n",
            "\n",
            "Sample categories in filtered dataset:\n",
            "['Restaurants, Food, Bubble Tea, Coffee & Tea, Bakeries'\n",
            " 'Brewpubs, Breweries, Food'\n",
            " 'Burgers, Fast Food, Sandwiches, Food, Ice Cream & Frozen Yogurt, Restaurants'\n",
            " ... 'Restaurants, Sandwiches, Convenience Stores, Coffee & Tea, Food'\n",
            " 'Cafes, Juice Bars & Smoothies, Coffee & Tea, Restaurants, Food'\n",
            " 'Specialty Food, Food, Coffee & Tea, Coffee Roasteries']\n",
            "Index(['business_id', 'name', 'address', 'latitude', 'longitude', 'stars',\n",
            "       'attributes', 'categories', 'is_michelin'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "non_food_terms = '|'.join(['Salon', 'Barber', 'Gym', 'Spa', 'Theater', 'Nightlife', 'Beauty', 'Barbershop', \"Active Life\",\n",
        "    \"Automotive\",\n",
        "    \"Beauty & Spas\",\n",
        "    \"Home Services\",\n",
        "    \"Health & Medical\",\n",
        "    \"Hotels & Travel\",\n",
        "    \"Local Services\",\n",
        "    \"Professional Services\",\n",
        "    \"Public Services & Government\",\n",
        "    \"Real Estate\",\n",
        "    \"Religious Organizations\",\n",
        "    \"Shopping & Retail\",\n",
        "    \"Transportation\",\n",
        "    \"Arts & Entertainment\",\n",
        "    \"Event Planning & Services\",\n",
        "    \"Education\",\n",
        "    \"Financial Services\",\n",
        "    \"Nightlife\",\n",
        "    \"Pets & Animal Services\",\n",
        "    \"Sports & Recreation\",\n",
        "    \"Miscellaneous Services\",\n",
        "    \"Shopping\", \"Women's Clothing\", \"Fashion\"\n",
        "])\n",
        "\n",
        "# Filter out non-food related businesses\n",
        "restaurant_df = restaurant_df[~restaurant_df['categories'].str.contains(non_food_terms, case=False, na=False)]\n",
        "picture_df = picture_df[picture_df['label'] != 'inside']\n",
        "picture_df = picture_df[picture_df['label'] != 'outside']\n",
        "picture_df = picture_df[picture_df['label'] != 'menu']\n",
        "# Keep only photos that belong to the filtered restaurants\n",
        "picture_df = picture_df[picture_df['business_id'].isin(restaurant_df['business_id'])]\n",
        "\n",
        "# Print statistics\n",
        "print(\"Number of food establishments:\", len(restaurant_df))\n",
        "print(\"Number of photos for food establishments:\", len(picture_df))\n",
        "print(\"\\nSample categories in filtered dataset:\")\n",
        "print(restaurant_df['categories'].unique())\n",
        "print(restaurant_df.columns)\n",
        "\n",
        "restaurant_df = restaurant_df.drop(columns=[\"categories\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "50c87186",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'Air conditioning': True, 'Car park': True, 'Interesting wine list': True, 'Wheelchair access': True, 'Cuisine': ['Traditional Cuisine'], 'RestaurantsPriceRange2': '3'}]\n",
            "['business_id', 'name', 'address', 'longitude', 'latitude', 'attributes', 'is_michelin', 'stars']\n",
            "[{'BusinessAcceptsCreditCards': 'True', 'BikeParking': 'True', 'RestaurantsTakeOut': 'True', 'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}\", 'RestaurantsPriceRange2': '1'}, {'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\", 'BusinessAcceptsCreditCards': 'True', 'RestaurantsPriceRange2': '3'}, {'RestaurantsGoodForGroups': 'True', 'OutdoorSeating': 'True', 'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}\", 'Ambience': \"{'touristy': False, 'hipster': False, 'romantic': False, 'divey': False, 'intimate': False, 'trendy': False, 'upscale': False, 'classy': False, 'casual': False}\", 'BusinessAcceptsCreditCards': 'True', 'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': False, 'dinner': False, 'brunch': False, 'breakfast': False}\", 'RestaurantsTakeOut': 'True', 'RestaurantsDelivery': 'None', 'RestaurantsReservations': 'False', 'GoodForKids': 'True'}, {'HasTV': 'True', 'RestaurantsGoodForGroups': 'False', 'RestaurantsTakeOut': 'True', 'Caters': 'False', 'RestaurantsReservations': 'False', 'BusinessAcceptsCreditCards': 'True', 'RestaurantsPriceRange2': '1', 'GoodForKids': 'True', 'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\", 'Ambience': \"{'touristy': False, 'hipster': False, 'romantic': False, 'divey': False, 'intimate': False, 'trendy': False, 'upscale': False, 'classy': False, 'casual': False}\", 'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': False, 'dinner': False, 'brunch': False, 'breakfast': False}\", 'RestaurantsDelivery': 'True'}, {'Air conditioning': True, 'Terrace': True, 'Wheelchair access': True, 'Cuisine': ['Modern Cuisine'], 'RestaurantsPriceRange2': '2'}, None, {'Car park': True, 'Terrace': True, 'Cuisine': ['Traditional Cuisine', 'International'], 'RestaurantsPriceRange2': '2'}, {'RestaurantsDelivery': 'True', 'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}\", 'BusinessAcceptsCreditCards': 'True', 'RestaurantsTakeOut': 'True'}, {'RestaurantsReservations': 'True', 'Ambience': \"{'romantic': False, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': False, 'trendy': True, 'upscale': False, 'casual': False}\", 'BusinessParking': \"{'garage': False, 'street': True, 'validated': False, 'lot': False, 'valet': True}\", 'WiFi': \"u'no'\", 'HasTV': 'False', 'NoiseLevel': \"u'average'\", 'GoodForKids': 'False', 'BusinessAcceptsCreditCards': 'True', 'RestaurantsTakeOut': 'False', 'RestaurantsGoodForGroups': 'True', 'Alcohol': \"u'full_bar'\", 'RestaurantsPriceRange2': '2', 'OutdoorSeating': 'True', 'RestaurantsAttire': \"u'casual'\", 'RestaurantsDelivery': 'False', 'HappyHour': 'True'}, {'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}\", 'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': False, 'brunch': False, 'breakfast': False}\", 'Alcohol': \"'beer_and_wine'\", 'NoiseLevel': \"'average'\", 'RestaurantsAttire': \"'casual'\", 'RestaurantsTakeOut': 'True', 'RestaurantsTableService': 'True', 'GoodForKids': 'True', 'HasTV': 'True', 'OutdoorSeating': 'False', 'BusinessAcceptsCreditCards': 'True', 'HappyHour': 'True', 'RestaurantsDelivery': 'True', 'RestaurantsPriceRange2': '1', 'Ambience': \"{'romantic': False, 'intimate': False, 'classy': False, 'hipster': False, 'divey': True, 'touristy': False, 'trendy': False, 'upscale': False, 'casual': False}\", 'WiFi': \"'no'\", 'RestaurantsGoodForGroups': 'True', 'RestaurantsReservations': 'False', 'BikeParking': 'True'}]\n"
          ]
        }
      ],
      "source": [
        "# union michelin_df and restaurant_df based on business_id as index\n",
        "michelin_df = michelin_df.set_index('business_id')\n",
        "print(michelin_df[\"attributes\"].sample(1).to_list())\n",
        "restaurant_df = restaurant_df.set_index('business_id')\n",
        "combined_df = pd.concat([michelin_df, restaurant_df], axis=0)\n",
        "combined_df = combined_df.reset_index()\n",
        "print(combined_df.columns.to_list())\n",
        "print(combined_df[\"attributes\"].sample(10).to_list())\n",
        "combined_df.to_csv('../data/combined_restaurants.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "1219e3cd",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def flatten_json(y, parent_key='', sep='_'):\n",
        "    items = {}\n",
        "    if isinstance(y, dict):\n",
        "        for k, v in y.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "            # Clean key names: remove special characters, replace spaces\n",
        "            new_key = re.sub(r'[^a-zA-Z0-9_]', '', new_key.replace(' ', '_'))\n",
        "            if isinstance(v, str):\n",
        "                try:\n",
        "                    # Handle Yelp's specific string format e.g. u'string_value'\n",
        "                    if v.startswith(\"u'\") and v.endswith(\"'\"):\n",
        "                        v = v[2:-1]\n",
        "                    elif v.startswith(\"'\") and v.endswith(\"'\"):\n",
        "                         v = v[1:-1]\n",
        "                    \n",
        "                    # Attempt to parse if it looks like a dict or list string\n",
        "                    # Use corrected string replacement logic\n",
        "                    if isinstance(v, str) and v.strip().startswith('{') and v.strip().endswith('}'):\n",
        "                        # More robust replacement for JSON parsing\n",
        "                        v_corrected = v.replace(\"\\\"\", \"'\") # Temp replace escaped quotes\n",
        "                        v_corrected = v_corrected.replace(\"'\", \"\\\"\") # Replace single with double\n",
        "                        v_corrected = v_corrected.replace(\"None\", \"null\").replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
        "                        nested_data = json.loads(v_corrected)\n",
        "                        items.update(flatten_json(nested_data, new_key, sep=sep))\n",
        "                    # elif isinstance(v, str) and v.strip().startswith('[') and v.strip().endswith(']'):\n",
        "                        # Handle lists if necessary - e.g., create dummy vars or join\n",
        "                        # items[new_key] = v # Placeholder: keep string for now\n",
        "                    else:\n",
        "                        items[new_key] = v # Keep as string if not JSON-like or list\n",
        "                except (json.JSONDecodeError, TypeError):\n",
        "                    items[new_key] = v # Keep original string if parsing fails\n",
        "            elif isinstance(v, dict):\n",
        "                items.update(flatten_json(v, new_key, sep=sep))\n",
        "            elif isinstance(v, list):\n",
        "                # Handle lists: Create dummy variables for each item\n",
        "                for item in v:\n",
        "                    item_key = re.sub(r'[^a-zA-Z0-9_]', '', str(item).replace(' ', '_'))\n",
        "                    items[f\"{new_key}_{item_key}\"] = 1 # Create a flag for each item\n",
        "            else:\n",
        "                items[new_key] = v\n",
        "    return items\n",
        "\n",
        "def parse_and_flatten(attr_input):\n",
        "    if isinstance(attr_input, dict): # Already a dict (from michelin data)\n",
        "        return flatten_json(attr_input)\n",
        "    if not isinstance(attr_input, str):\n",
        "        return {}\n",
        "    try:\n",
        "        # More robust replacement for initial JSON parsing\n",
        "        attr_str_corrected = attr_input.replace(\"\\\"\", \"'\") # Temp replace escaped quotes\n",
        "        attr_str_corrected = attr_str_corrected.replace(\"'\", \"\\\"\") # Replace single with double\n",
        "        attr_str_corrected = attr_str_corrected.replace(\"None\", \"null\").replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
        "        data = json.loads(attr_str_corrected)\n",
        "        return flatten_json(data)\n",
        "    except (json.JSONDecodeError, TypeError):\n",
        "        # If it fails, return empty dict\n",
        "        # print(f\"Failed to parse: {attr_input}\") # Optional: for debugging\n",
        "        return {}\n",
        "\n",
        "def extract_and_encode_attributes(df):\n",
        "    \"\"\"\n",
        "    Extracts nested JSON attributes, flattens them, encodes them numerically,\n",
        "    and merges them back into the DataFrame.\n",
        "    \"\"\"\n",
        "    if 'attributes' not in df.columns:\n",
        "        print(\"Column 'attributes' not found.\")\n",
        "        return df\n",
        "        \n",
        "    # Apply parsing and flattening row-wise\n",
        "    flattened_attrs = df['attributes'].apply(parse_and_flatten)\n",
        "\n",
        "    # Create a DataFrame from the flattened attributes\n",
        "    attrs_df = pd.DataFrame(flattened_attrs.tolist(), index=df.index)\n",
        "    print(f\"Extracted {attrs_df.shape[1]} attribute columns.\")\n",
        "\n",
        "    # Combine with the original DataFrame (excluding the original 'attributes' column)\n",
        "    df_processed = pd.concat([df.drop(columns=['attributes']), attrs_df], axis=1)\n",
        "\n",
        "    # --- Encoding ---\n",
        "    map_dict = {\n",
        "        'True': 1, 'true': 1, '1': 1, True: 1,\n",
        "        'False': 0, 'false': 0, '0': 0, False: 0,\n",
        "        'None': 0, 'none': 0, None: 0, 'null': 0, '': 0,\n",
        "        'yes': 1, 'no': 0, # Add common boolean words\n",
        "        # Handle Yelp specific strings like 'full_bar', 'beer_and_wine'\n",
        "        'full_bar': 1, 'beer_and_wine': 1, # For Alcohol (treat 'none' as 0 above)\n",
        "        'casual': 0, 'dressy': 1, 'formal': 2, # For Attire (example ordinal)\n",
        "        'quiet': 0, 'average': 1, 'loud': 2, 'very_loud': 3 # For NoiseLevel (example ordinal)\n",
        "        # Price range ('RestaurantsPriceRange2') will be handled separately\n",
        "    }\n",
        "\n",
        "    new_cols = attrs_df.columns\n",
        "    object_cols_to_process = df_processed[new_cols].select_dtypes(include=['object']).columns\n",
        "    \n",
        "    # Identify the likely price column name (handle potential variations from flattening)\n",
        "    price_col_name = None\n",
        "    potential_price_cols = [col for col in new_cols if 'RestaurantsPriceRange' in col]\n",
        "    if potential_price_cols:\n",
        "        price_col_name = potential_price_cols[0] # Assume the first match is the one\n",
        "        print(f\"Identified price column as: {price_col_name}\")\n",
        "    else:\n",
        "        print(\"Warning: Price range column ('RestaurantsPriceRange2') not found in extracted attributes.\")\n",
        "\n",
        "    for col in object_cols_to_process:\n",
        "        # *** Skip the price column from general mapping *** \n",
        "        if col == price_col_name:\n",
        "            continue\n",
        "            \n",
        "        # Attempt direct mapping first for common boolean/categorical strings\n",
        "        # Create a temporary mapped series to check effectiveness\n",
        "        mapped_series = df_processed[col].map(map_dict)\n",
        "        \n",
        "        # If a significant portion was mapped, apply it\n",
        "        if mapped_series.notna().sum() > 0.1 * len(df_processed): # Heuristic: if >10% mapped\n",
        "             df_processed[col] = mapped_series\n",
        "        else:\n",
        "             # If mapping didn't work well, try numeric conversion\n",
        "             numeric_series = pd.to_numeric(df_processed[col], errors='coerce')\n",
        "             if numeric_series.notna().sum() > 0.1 * len(df_processed):\n",
        "                  df_processed[col] = numeric_series\n",
        "             # else: # Optional: Consider one-hot encoding for low-cardinality categoricals\n",
        "                 # unique_count = df_processed[col].nunique()\n",
        "                 # if 1 < unique_count < 20: # Heuristic for one-hot encoding\n",
        "                 #     print(f\"One-hot encoding column: {col}\")\n",
        "                 #     dummies = pd.get_dummies(df_processed[col], prefix=col, dummy_na=False)\n",
        "                 #     df_processed = pd.concat([df_processed.drop(columns=[col]), dummies], axis=1)\n",
        "                 # else:\n",
        "                 #     print(f\"Dropping object column with high cardinality or unmappable: {col}\")\n",
        "                 #     df_processed = df_processed.drop(columns=[col], errors='ignore')\n",
        "    \n",
        "    # *** Specifically handle the price column *** \n",
        "    if price_col_name and price_col_name in df_processed.columns:\n",
        "        # Convert to numeric, coercing errors (e.g., empty strings) to NaN\n",
        "        df_processed[price_col_name] = pd.to_numeric(df_processed[price_col_name], errors='coerce')\n",
        "        # Fill any resulting NaNs (e.g., from non-numeric entries or missing values) with 0\n",
        "        # Consider if 0 is the best fill value, maybe median/mean if appropriate\n",
        "        df_processed[price_col_name] = df_processed[price_col_name].fillna(0)\n",
        "        print(f\"Processed price column '{price_col_name}' numerically.\")\n",
        "        \n",
        "    # Convert original boolean columns (like is_michelin) to int if they exist and are bool type\n",
        "    for col in df_processed.select_dtypes(include=['bool']).columns:\n",
        "        df_processed[col] = df_processed[col].astype(int)\n",
        "\n",
        "    # Fill NaN values - strategy: fill with 0 for numeric/mapped cols\n",
        "    # This will also cover NaNs in numeric columns not handled above\n",
        "    numeric_cols = df_processed.select_dtypes(include=np.number).columns\n",
        "    df_processed[numeric_cols] = df_processed[numeric_cols].fillna(0)\n",
        "\n",
        "    # Convert float columns that should be int (like mapped booleans, counts, price ranges)\n",
        "    for col in numeric_cols:\n",
        "        # Check if column exists and is numeric\n",
        "        if col in df_processed.columns and pd.api.types.is_numeric_dtype(df_processed[col]):\n",
        "            # Avoid converting genuine floats like lat/lon/stars by checking if all values are integers\n",
        "            try:\n",
        "                # Check after filling NaNs\n",
        "                is_integer_like = (df_processed[col] % 1 == 0).all()\n",
        "            except TypeError:\n",
        "                is_integer_like = False # Handle potential non-numeric types if any issue\n",
        "                \n",
        "            # Also skip the price column here if it was float and meant to stay float (unlikely for price range)\n",
        "            if is_integer_like and col not in ['latitude', 'longitude', 'stars']:\n",
        "                # Convert to standard int (already filled NaNs)\n",
        "                df_processed[col] = df_processed[col].astype(int)\n",
        "\n",
        "    # Drop remaining object columns that were not processed (likely high cardinality text)\n",
        "    final_object_cols = df_processed.select_dtypes(include=['object']).columns\n",
        "    # Keep essential identifiers\n",
        "    keep_objects = ['business_id', 'name', 'address'] \n",
        "    cols_to_drop = [col for col in final_object_cols if col not in keep_objects]\n",
        "    if cols_to_drop:\n",
        "        print(f\"Dropping remaining unprocessed object columns: {cols_to_drop}\")\n",
        "        df_processed = df_processed.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    print(f\"DataFrame shape after processing attributes: {df_processed.shape}\")\n",
        "    return df_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "974a96e1",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 377 attribute columns.\n",
            "Identified price column as: RestaurantsPriceRange2\n",
            "Identified price column as: RestaurantsPriceRange2\n",
            "Processed price column 'RestaurantsPriceRange2' numerically.\n",
            "Processed price column 'RestaurantsPriceRange2' numerically.\n",
            "Dropping remaining unprocessed object columns: ['Interesting_wine_list', 'Valet_parking', 'Wheelchair_access', 'Garden_or_park', 'Restaurant_offering_vegetarian_menus', 'Car_park', 'Great_view', 'Counter_dining', 'Notable_sake_list', 'Shoes_must_be_removed', 'Cash_only', 'Brunch', 'Credit_cards_not_accepted', 'Bring_your_own_bottle', 'Cash_only__lunch', 'Foreign_credit_cards_not_accepted', 'Booking_essential', 'Booking_essential__dinner', 'ByAppointmentOnly', 'BusinessParking', 'Ambience', 'CoatCheck', 'DriveThru', 'BusinessAcceptsBitcoin', 'BYOB', 'GoodForMeal', 'Corkage', 'BYOBCorkage', 'Smoking', 'RestaurantsCounterService', 'BestNights_monday', 'BestNights_tuesday', 'BestNights_friday', 'BestNights_wednesday', 'BestNights_thursday', 'BestNights_sunday', 'BestNights_saturday', 'Music_dj', 'Music_background_music', 'Music_jukebox', 'Music_live', 'Music_video', 'Music_karaoke', 'GoodForDancing', 'Open24Hours', 'AgesAllowed', 'DietaryRestrictions_dairyfree', 'DietaryRestrictions_glutenfree', 'DietaryRestrictions_vegan', 'DietaryRestrictions_kosher', 'DietaryRestrictions_halal', 'DietaryRestrictions_soyfree', 'DietaryRestrictions_vegetarian', 'Music_no_music', 'DietaryRestrictions', 'AcceptsInsurance']\n",
            "DataFrame shape after processing attributes: (68782, 328)\n",
            "Dropping remaining unprocessed object columns: ['Interesting_wine_list', 'Valet_parking', 'Wheelchair_access', 'Garden_or_park', 'Restaurant_offering_vegetarian_menus', 'Car_park', 'Great_view', 'Counter_dining', 'Notable_sake_list', 'Shoes_must_be_removed', 'Cash_only', 'Brunch', 'Credit_cards_not_accepted', 'Bring_your_own_bottle', 'Cash_only__lunch', 'Foreign_credit_cards_not_accepted', 'Booking_essential', 'Booking_essential__dinner', 'ByAppointmentOnly', 'BusinessParking', 'Ambience', 'CoatCheck', 'DriveThru', 'BusinessAcceptsBitcoin', 'BYOB', 'GoodForMeal', 'Corkage', 'BYOBCorkage', 'Smoking', 'RestaurantsCounterService', 'BestNights_monday', 'BestNights_tuesday', 'BestNights_friday', 'BestNights_wednesday', 'BestNights_thursday', 'BestNights_sunday', 'BestNights_saturday', 'Music_dj', 'Music_background_music', 'Music_jukebox', 'Music_live', 'Music_video', 'Music_karaoke', 'GoodForDancing', 'Open24Hours', 'AgesAllowed', 'DietaryRestrictions_dairyfree', 'DietaryRestrictions_glutenfree', 'DietaryRestrictions_vegan', 'DietaryRestrictions_kosher', 'DietaryRestrictions_halal', 'DietaryRestrictions_soyfree', 'DietaryRestrictions_vegetarian', 'Music_no_music', 'DietaryRestrictions', 'AcceptsInsurance']\n",
            "DataFrame shape after processing attributes: (68782, 328)\n"
          ]
        }
      ],
      "source": [
        "# extract attributes and create recommendation features\n",
        "combined_df = extract_and_encode_attributes(combined_df)\n",
        "# combined_df = combined_df.drop(columns=['attributes']) # Drop is now handled inside the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "1503de4f",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "business_id               object\n",
            "name                      object\n",
            "address                   object\n",
            "longitude                float64\n",
            "latitude                 float64\n",
            "                          ...   \n",
            "GoodForMeal_lunch          int64\n",
            "GoodForMeal_dinner         int64\n",
            "GoodForMeal_brunch         int64\n",
            "GoodForMeal_breakfast      int64\n",
            "NoiseLevel                 int64\n",
            "Length: 328, dtype: object\n",
            "(68782, 328)\n",
            "['business_id', 'name', 'address', 'longitude', 'latitude', 'is_michelin', 'stars', 'Air_conditioning', 'Cuisine_Korean', 'Cuisine_Korean_Contemporary', 'RestaurantsPriceRange2', 'Cuisine_Creative_British', 'Cuisine_French', 'Cuisine_Modern_Cuisine', 'Cuisine_Creative', 'Cuisine_Classic_French', 'Cuisine_Modern_French', 'Cuisine_Modern_British', 'Terrace', 'Cuisine_Contemporary', 'Cuisine_Seafood', 'Cuisine_Vegan', 'Cuisine_Innovative', 'Cuisine_Japanese', 'Cuisine_Sushi', 'Cuisine_American', 'Cuisine_Noodles', 'Cuisine_Naengmyeon', 'Cuisine_Gomtang', 'Cuisine_Dwaejigukbap', 'Cuisine_Southern_Thai', 'Cuisine_Asturian', 'Cuisine_Traditional_Cuisine', 'Cuisine_Italian_Contemporary', 'Cuisine_Alpine', 'Cuisine_Mediterranean_Cuisine', 'Cuisine_Seasonal_Cuisine', 'Cuisine_Country_cooking', 'Cuisine_Farm_to_table', 'Cuisine_French_Contemporary', 'Cuisine_Chinese', 'Cuisine_Taizhou', 'Cuisine_Chao_Zhou', 'Cuisine_Taiwanese_contemporary', 'Cuisine_Singaporean', 'Cuisine_Cantonese', 'Cuisine_Californian', 'Cuisine_Asian', 'Cuisine_European_Contemporary', 'Cuisine_Regional_Cuisine', 'Cuisine_International', 'Cuisine_Classic_Cuisine', 'Cuisine_Italian', 'Cuisine_Creative_French', 'Cuisine_Portuguese', 'Cuisine_Turkish', 'Cuisine_Indian', 'Cuisine_Traditional_British', 'Cuisine_Austrian', 'Cuisine_Greek', 'Cuisine_Hungarian', 'Cuisine_Scandinavian', 'Cuisine_Alsatian', 'Cuisine_American_Contemporary', 'Cuisine_Thai_contemporary', 'Cuisine_German', 'Cuisine_Thai', 'Cuisine_Italian_and_Japanese', 'Cuisine_Catalan', 'Cuisine_Castilian', 'Cuisine_Vegetarian', 'Cuisine_Malaysian', 'Cuisine_Tuscan', 'Cuisine_Sicilian', 'Cuisine_Piedmontese', 'Cuisine_Japanese_Contemporary', 'Cuisine_Fusion', 'Cuisine_Sharing', 'Cuisine_Tempura', 'Cuisine_Spanish', 'Cuisine_Beijing_Cuisine', 'Cuisine_Shanghainese', 'Cuisine_Shandong', 'Cuisine_Organic', 'Cuisine_Asian_Influences', 'Cuisine_Sichuan', 'Cuisine_Spanish_Contemporary', 'Cuisine_Asian_Contemporary', 'Cuisine_Mexican', 'Cuisine_British_Contemporary', 'Cuisine_Swedish', 'Cuisine_Brazilian', 'Cuisine_Hunanese', 'Cuisine_Huaiyang', 'Cuisine_African', 'Cuisine_European', 'Cuisine_Irish', 'Cuisine_Grills', 'Cuisine_South_American', 'Cuisine_ItalianAmerican', 'Cuisine_Israeli', 'Cuisine_Middle_Eastern', 'Cuisine_Latin_American', 'Cuisine_Yakitori', 'Cuisine_Steakhouse', 'Cuisine_Colombian', 'Cuisine_Peruvian', 'Cuisine_Lebanese', 'Cuisine_Filipino', 'Cuisine_Fujian', 'Cuisine_Street_Food', 'Cuisine_Basque', 'Cuisine_Dumplings', 'Cuisine_Galician', 'Cuisine_Andalusian', 'Cuisine_World_Cuisine', 'Cuisine_Jiangzhe', 'Cuisine_Chinese_Contemporary', 'Cuisine_Ningbo', 'Cuisine_Dim_Sum', 'Cuisine_Peranakan', 'Cuisine_Barbecue', 'Cuisine_Southern', 'Cuisine_Ligurian', 'Cuisine_Campanian', 'Cuisine_Meats_and_Grills', 'Cuisine_Umbrian', 'Cuisine_Cuisine_from_the_Marches', 'Cuisine_Cuisine_from_Abruzzo', 'Cuisine_Calabrian', 'Cuisine_Apulian', 'Cuisine_Emilian', 'Cuisine_Cuisine_from_the_Aosta_Valley', 'Cuisine_Cuisine_from_Romagna', 'Cuisine_Sardinian', 'Cuisine_Venetian', 'Cuisine_Cuisine_from_Lazio', 'Cuisine_Lombardian', 'Cuisine_Emirati_Cuisine', 'Cuisine_Swiss', 'Cuisine_Asian_and_Western', 'Cuisine_Shojin', 'Cuisine_Beef', 'Cuisine_Unagi__Freshwater_Eel', 'Cuisine_Crab_Specialities', 'Cuisine_Dongbei', 'Cuisine_North_American', 'Cuisine_Duck_Specialities', 'Cuisine_Taiwanese', 'Cuisine_Hang_Zhou', 'Cuisine_Indian_Vegetarian', 'Cuisine_Vietnamese_Contemporary', 'Cuisine_Teppanyaki', 'Cuisine_Vietnamese', 'Cuisine_Croatian', 'Cuisine_Teochew', 'Cuisine_Norwegian', 'Cuisine_Danish', 'Cuisine_Zhejiang', 'Cuisine_Fugu__Pufferfish', 'Cuisine_Russian', 'Cuisine_North_African', 'Cuisine_Provenal', 'Cuisine_Corsican', 'Cuisine_Shun_Tak', 'Cuisine_Cantonese_Roast_Meats', 'Cuisine_Pakistani', 'Cuisine_Noodles_and_Congee', 'Cuisine_Belgian', 'Cuisine_Home_Cooking', 'Cuisine_Mandu', 'Cuisine_Ramen', 'Cuisine_Jokbal', 'Cuisine_Memilguksu', 'Cuisine_Seolleongtang', 'Cuisine_Soba', 'Cuisine_Dubu', 'Cuisine_Kalguksu', 'Cuisine_Doganitang', 'Cuisine_Sujebi', 'Cuisine_Bibimbap', 'Cuisine_Gejang', 'Cuisine_Bulgogi', 'Cuisine_Chueotang', 'Cuisine_Yukhoe', 'Cuisine_Udon', 'Cuisine_Lyonnaise', 'Cuisine_Persian', 'Cuisine_South_East_Asian', 'Cuisine_South_Indian', 'Cuisine_Sri_Lankan', 'Cuisine_Scottish', 'Cuisine_Creole', 'Cuisine_Cajun', 'Cuisine_South_African', 'Cuisine_Izakaya', 'Cuisine_Regional_European', 'Cuisine_Pizza', 'Cuisine_Moroccan', 'Cuisine_Central_Asian', 'Cuisine_Isan', 'Cuisine_TexMex', 'Cuisine_Burmese', 'Cuisine_Chicken_Specialities', 'Cuisine_Deli', 'Cuisine_Cambodian', 'Cuisine_Polish', 'Cuisine_Roman', 'Cuisine_Tibetan', 'Cuisine_Czech', 'Cuisine_Gastropub', 'Cuisine_Lao', 'Cuisine_Bakery', 'Cuisine_Caribbean', 'Cuisine_Afghan', 'Cuisine_English', 'Cuisine_Congee', 'Cuisine_Small_eats', 'Cuisine_Yunnanese', 'Cuisine_ThaiChinese', 'Cuisine_Northern_Thai', 'Cuisine_Rice_Dishes', 'Cuisine_Pork', 'Cuisine_Hakkanese', 'Cuisine_Egyptian', 'Cuisine_Jamaican', 'Cuisine_Cuisine_from_Valtellina', 'Cuisine_Cuisine_from_Basilicata', 'Cuisine_Mantuan', 'Cuisine_Friulian', 'Cuisine_South_Tyrolean', 'Cuisine_Armenian', 'Cuisine_Venezuelan', 'Cuisine_Tonkatsu', 'Cuisine_Yoshoku', 'Cuisine_Onigiri', 'Cuisine_Hubei', 'Cuisine_Hotpot', 'Cuisine_Indonesian', 'Cuisine_Balinese', 'Cuisine_Milanese', 'Cuisine_Thai_and_Vietnamese', 'Cuisine_Ethiopian', 'Cuisine_Balkan', 'Cuisine_Xibei', 'Cuisine_Smrrebrd', 'Cuisine_Kushiage', 'Cuisine_Cuban', 'Cuisine_Nepali', 'Cuisine_Oden', 'Cuisine_Okonomiyaki', 'Cuisine_Obanzai', 'Cuisine_Bavarian', 'Cuisine_Savoyard', 'Cuisine_Breton', 'Cuisine_Chiu_Chow', 'Cuisine_Macanese', 'Cuisine_Singaporean_and_Malaysian', 'Cuisine_Xinjiang', 'Cuisine_Cuisine_from_South_West_France', 'Cuisine_Argentinian', 'Cuisine_Australian_Contemporary', 'Cuisine_Meats_and_Seafood', 'Cuisine_Japanese_Steakhouse', 'Cuisine_Oyster_Specialities', 'Cuisine_Eastern_European', 'Cuisine_Shabushabu', 'Cuisine_Lamb_Specialities', 'Cuisine_Hui_Cuisine', 'Cuisine_Fish_and_Chips', 'Cuisine_Shellfish_Specialities', 'Cuisine_Cheese', 'Cuisine_Fondue_and_Raclette', 'Cuisine_Sukiyaki', 'Cuisine_Shaanxi', 'Cuisine_Hunanese_and_Sichuan', 'Cuisine_Puerto_Rican', 'Cuisine_Curry', 'Cuisine_Hainanese', 'Cuisine_Finnish', 'Cuisine_406_Kameyacho', 'Cuisine_Nakagyoku', 'Cuisine_Kyoto', 'Cuisine_6040941', 'Cuisine_Japan', 'Cuisine_Swabian', 'Cuisine_Cuisine_from_FrancheComt', 'Cuisine_Burgundian', 'Cuisine_Crpe', 'Cuisine_Flemish', 'RestaurantsDelivery', 'OutdoorSeating', 'BusinessAcceptsCreditCards', 'BusinessParking_garage', 'BusinessParking_street', 'BusinessParking_validated', 'BusinessParking_lot', 'BusinessParking_valet', 'BikeParking', 'RestaurantsTakeOut', 'WiFi', 'Alcohol', 'Caters', 'WheelchairAccessible', 'GoodForKids', 'RestaurantsAttire', 'RestaurantsReservations', 'DogsAllowed', 'RestaurantsTableService', 'RestaurantsGoodForGroups', 'HasTV', 'HappyHour', 'Ambience_touristy', 'Ambience_hipster', 'Ambience_romantic', 'Ambience_divey', 'Ambience_intimate', 'Ambience_trendy', 'Ambience_upscale', 'Ambience_classy', 'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight', 'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch', 'GoodForMeal_breakfast', 'NoiseLevel']\n",
            "Boolean columns found: []\n",
            "Object columns to check/map for boolean-like values: []\n",
            "(68782, 328)\n",
            "Checking dtypes of boolean-like columns after conversion:\n",
            "   is_michelin  Terrace  Air_conditioning\n",
            "0            1        0                 1\n",
            "1            1        0                 1\n",
            "2            1        0                 1\n",
            "3            1        0                 1\n",
            "4            1        0                 1\n",
            "is_michelin         int64\n",
            "Terrace             int64\n",
            "Air_conditioning    int64\n",
            "dtype: object\n",
            "(68782, 328)\n",
            "Checking dtypes of boolean-like columns after conversion:\n",
            "   is_michelin  Terrace  Air_conditioning\n",
            "0            1        0                 1\n",
            "1            1        0                 1\n",
            "2            1        0                 1\n",
            "3            1        0                 1\n",
            "4            1        0                 1\n",
            "is_michelin         int64\n",
            "Terrace             int64\n",
            "Air_conditioning    int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# check output based on column datatypes\n",
        "print(combined_df.dtypes)\n",
        "print(combined_df.shape)\n",
        "print(combined_df.columns.to_list())\n",
        "\n",
        "# Identify boolean columns (including those potentially created from attributes)\n",
        "bool_cols = combined_df.select_dtypes(include=['bool']).columns\n",
        "print(f\"Boolean columns found: {list(bool_cols)}\")\n",
        "for col in bool_cols:\n",
        "    combined_df[col] = combined_df[col].astype(int)\n",
        "\n",
        "# Convert is_michelin specifically if it wasn't bool type already\n",
        "if 'is_michelin' in combined_df.columns and combined_df['is_michelin'].dtype != 'int':\n",
        "    # Ensure it's treated as boolean before converting to int\n",
        "    combined_df['is_michelin'] = combined_df['is_michelin'].astype(bool).astype(int)\n",
        "\n",
        "obj_bool_cols = [\n",
        "    \"Air conditioning\",\n",
        "    \"Interesting wine list\",\n",
        "    \"Valet parking\",\n",
        "    \"Wheelchair access\",\n",
        "    \"Garden or park\",\n",
        "    \"Restaurant offering vegetarian menus\",\n",
        "    \"Car park\",\n",
        "    \"Great view\",\n",
        "    \"Terrace\",\n",
        "    \"Counter dining\",\n",
        "    \"Notable sake list\",\n",
        "    \"Shoes must be removed\",\n",
        "    \"Cash only\",\n",
        "    \"Brunch\",\n",
        "    \"Credit cards not accepted\",\n",
        "    \"Bring your own bottle\",\n",
        "    \"Cash only - lunch\",\n",
        "    \"Foreign credit cards not accepted\"\n",
        "]\n",
        "\n",
        "# Clean column names in obj_bool_cols list to match flattened names\n",
        "obj_bool_cols = [re.sub(r'[^a-zA-Z0-9_]', '', col.replace(' ', '_')) for col in obj_bool_cols]\n",
        "\n",
        "# Filter list to columns that actually exist in the dataframe after flattening\n",
        "obj_bool_cols = [col for col in obj_bool_cols if col in combined_df.columns]\n",
        "\n",
        "# Check which of these are still object type (meaning initial mapping might have missed some cases)\n",
        "obj_cols_needing_map = [col for col in obj_bool_cols if combined_df[col].dtype == 'object']\n",
        "\n",
        "print(f\"Object columns to check/map for boolean-like values: {obj_cols_needing_map}\")\n",
        "\n",
        "map_dict = {'True': 1, 'true': 1, '1': 1, True: 1,\n",
        "            'False': 0, 'false': 0, '0': 0, False: 0,\n",
        "            'None': 0, 'none': 0, None: 0, 'null': 0, '': 0,\n",
        "            'yes': 1, 'no': 0}\n",
        "\n",
        "for col in obj_cols_needing_map:\n",
        "    # Apply mapping, coerce others to NaN\n",
        "    combined_df[col] = combined_df[col].map(map_dict)\n",
        "    # Convert to numeric, errors='coerce' handles original non-mappable values -> NaN\n",
        "    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
        "\n",
        "# fill missing values with 0 (redundant if done in function, but safe)\n",
        "numeric_cols = combined_df.select_dtypes(include=np.number).columns\n",
        "combined_df[numeric_cols] = combined_df[numeric_cols].fillna(0)\n",
        "\n",
        "# Ensure final integer type for all boolean-like columns\n",
        "# Combine original bool cols, obj_bool_cols, and is_michelin\n",
        "final_bool_cols = list(bool_cols) + obj_bool_cols + ['is_michelin']\n",
        "# Ensure unique and existing columns\n",
        "final_bool_cols = list(set([col for col in final_bool_cols if col in combined_df.columns]))\n",
        "\n",
        "for col in final_bool_cols:\n",
        "     # Check if column exists and is numeric but not integer\n",
        "     if col in combined_df.columns and pd.api.types.is_numeric_dtype(combined_df[col]) and not pd.api.types.is_integer_dtype(combined_df[col]):\n",
        "         # Check if conversion to int is safe (no NaNs, all are whole numbers)\n",
        "         if combined_df[col].isnull().sum() == 0 and (combined_df[col] % 1 == 0).all():\n",
        "             combined_df[col] = combined_df[col].astype(int)\n",
        "         else:\n",
        "             # Handle cases with NaNs or non-integers if necessary, e.g., fillna then convert\n",
        "             print(f\"Warning: Column {col} could not be safely converted to int. Contains NaNs or non-integers.\")\n",
        "             # Apply fillna(0) and convert, accepting potential data change\n",
        "             combined_df[col] = combined_df[col].fillna(0).astype(int)\n",
        "\n",
        "# check output based on column datatypes\n",
        "print(combined_df.shape)\n",
        "print(\"Checking dtypes of boolean-like columns after conversion:\")\n",
        "print(combined_df[final_bool_cols].head())\n",
        "print(combined_df[final_bool_cols].dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "60426dc3",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results:\n",
            "Total pictures: 81941\n",
            "Pictures with valid restaurant links: 81941\n",
            "Pictures with invalid restaurant links: 0\n",
            "\n",
            "All pictures are linked to valid restaurants!\n"
          ]
        }
      ],
      "source": [
        "# New cell for validation\n",
        "# Check if all pictures link to valid restaurants\n",
        "# get business_ids of all restaurants in combined_df\n",
        "all_valid_business_ids = set(combined_df['business_id'])\n",
        "invalid_pictures = picture_df[~picture_df['business_id'].isin(all_valid_business_ids)]\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(f\"Total pictures: {len(picture_df)}\")\n",
        "print(f\"Pictures with valid restaurant links: {len(picture_df) - len(invalid_pictures)}\")\n",
        "print(f\"Pictures with invalid restaurant links: {len(invalid_pictures)}\")\n",
        "\n",
        "if len(invalid_pictures) > 0:\n",
        "    print(\"\\nSample of invalid picture entries:\")\n",
        "    print(invalid_pictures.head())\n",
        "else:\n",
        "    print(\"\\nAll pictures are linked to valid restaurants!\")\n",
        "\n",
        "# Optional: Remove any invalid pictures if found\n",
        "if len(invalid_pictures) > 0:\n",
        "    picture_df = picture_df[picture_df['business_id'].isin(all_valid_business_ids)]\n",
        "    print(f\"\\nCleaned dataset now contains {len(picture_df)} valid pictures\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "d3971be8",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Photos folder not found at: ../data/photos\n"
          ]
        }
      ],
      "source": [
        "# parse photos folder and remove any photos that are not in the cleaned dataset\n",
        "import os\n",
        "\n",
        "# Create a set of valid photo IDs\n",
        "valid_photo_ids = set(picture_df['photo_id'])\n",
        "\n",
        "# Define the path to the photos folder\n",
        "photos_folder = '../data/photos'\n",
        "\n",
        "# Iterate over all files in the photos folder\n",
        "if os.path.exists(photos_folder):\n",
        "    for filename in os.listdir(photos_folder):\n",
        "        # Extract the photo ID from the filename\n",
        "        photo_id = filename.split('.')[0]\n",
        "        \n",
        "        # Check if the photo ID is not in the valid set\n",
        "        if photo_id not in valid_photo_ids:\n",
        "            # Construct the full path to the file\n",
        "            file_path = os.path.join(photos_folder, filename)\n",
        "            \n",
        "            # Remove the file\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"Removed invalid photo: {filename}\")\n",
        "            except OSError as e:\n",
        "                print(f\"Error removing file {file_path}: {e}\")\n",
        "                \n",
        "    # Check the number of photos in the folder\n",
        "    print(f\"Remaining photos in the folder: {len(os.listdir(photos_folder))}\")\n",
        "else:\n",
        "    print(f\"Photos folder not found at: {photos_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "712a05fe",
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 1 3 2 0]\n",
            "Columns for model training: ['business_id', 'longitude', 'latitude', 'stars', 'Air_conditioning', 'Cuisine_Korean', 'Cuisine_Korean_Contemporary', 'RestaurantsPriceRange2', 'Cuisine_Creative_British', 'Cuisine_French', 'Cuisine_Modern_Cuisine', 'Cuisine_Creative', 'Cuisine_Classic_French', 'Cuisine_Modern_French', 'Cuisine_Modern_British', 'Terrace', 'Cuisine_Contemporary', 'Cuisine_Seafood', 'Cuisine_Vegan', 'Cuisine_Innovative', 'Cuisine_Japanese', 'Cuisine_Sushi', 'Cuisine_American', 'Cuisine_Noodles', 'Cuisine_Naengmyeon', 'Cuisine_Gomtang', 'Cuisine_Dwaejigukbap', 'Cuisine_Southern_Thai', 'Cuisine_Asturian', 'Cuisine_Traditional_Cuisine', 'Cuisine_Italian_Contemporary', 'Cuisine_Alpine', 'Cuisine_Mediterranean_Cuisine', 'Cuisine_Seasonal_Cuisine', 'Cuisine_Country_cooking', 'Cuisine_Farm_to_table', 'Cuisine_French_Contemporary', 'Cuisine_Chinese', 'Cuisine_Taizhou', 'Cuisine_Chao_Zhou', 'Cuisine_Taiwanese_contemporary', 'Cuisine_Singaporean', 'Cuisine_Cantonese', 'Cuisine_Californian', 'Cuisine_Asian', 'Cuisine_European_Contemporary', 'Cuisine_Regional_Cuisine', 'Cuisine_International', 'Cuisine_Classic_Cuisine', 'Cuisine_Italian', 'Cuisine_Creative_French', 'Cuisine_Portuguese', 'Cuisine_Turkish', 'Cuisine_Indian', 'Cuisine_Traditional_British', 'Cuisine_Austrian', 'Cuisine_Greek', 'Cuisine_Hungarian', 'Cuisine_Scandinavian', 'Cuisine_Alsatian', 'Cuisine_American_Contemporary', 'Cuisine_Thai_contemporary', 'Cuisine_German', 'Cuisine_Thai', 'Cuisine_Italian_and_Japanese', 'Cuisine_Catalan', 'Cuisine_Castilian', 'Cuisine_Vegetarian', 'Cuisine_Malaysian', 'Cuisine_Tuscan', 'Cuisine_Sicilian', 'Cuisine_Piedmontese', 'Cuisine_Japanese_Contemporary', 'Cuisine_Fusion', 'Cuisine_Sharing', 'Cuisine_Tempura', 'Cuisine_Spanish', 'Cuisine_Beijing_Cuisine', 'Cuisine_Shanghainese', 'Cuisine_Shandong', 'Cuisine_Organic', 'Cuisine_Asian_Influences', 'Cuisine_Sichuan', 'Cuisine_Spanish_Contemporary', 'Cuisine_Asian_Contemporary', 'Cuisine_Mexican', 'Cuisine_British_Contemporary', 'Cuisine_Swedish', 'Cuisine_Brazilian', 'Cuisine_Hunanese', 'Cuisine_Huaiyang', 'Cuisine_African', 'Cuisine_European', 'Cuisine_Irish', 'Cuisine_Grills', 'Cuisine_South_American', 'Cuisine_ItalianAmerican', 'Cuisine_Israeli', 'Cuisine_Middle_Eastern', 'Cuisine_Latin_American', 'Cuisine_Yakitori', 'Cuisine_Steakhouse', 'Cuisine_Colombian', 'Cuisine_Peruvian', 'Cuisine_Lebanese', 'Cuisine_Filipino', 'Cuisine_Fujian', 'Cuisine_Street_Food', 'Cuisine_Basque', 'Cuisine_Dumplings', 'Cuisine_Galician', 'Cuisine_Andalusian', 'Cuisine_World_Cuisine', 'Cuisine_Jiangzhe', 'Cuisine_Chinese_Contemporary', 'Cuisine_Ningbo', 'Cuisine_Dim_Sum', 'Cuisine_Peranakan', 'Cuisine_Barbecue', 'Cuisine_Southern', 'Cuisine_Ligurian', 'Cuisine_Campanian', 'Cuisine_Meats_and_Grills', 'Cuisine_Umbrian', 'Cuisine_Cuisine_from_the_Marches', 'Cuisine_Cuisine_from_Abruzzo', 'Cuisine_Calabrian', 'Cuisine_Apulian', 'Cuisine_Emilian', 'Cuisine_Cuisine_from_the_Aosta_Valley', 'Cuisine_Cuisine_from_Romagna', 'Cuisine_Sardinian', 'Cuisine_Venetian', 'Cuisine_Cuisine_from_Lazio', 'Cuisine_Lombardian', 'Cuisine_Emirati_Cuisine', 'Cuisine_Swiss', 'Cuisine_Asian_and_Western', 'Cuisine_Shojin', 'Cuisine_Beef', 'Cuisine_Unagi__Freshwater_Eel', 'Cuisine_Crab_Specialities', 'Cuisine_Dongbei', 'Cuisine_North_American', 'Cuisine_Duck_Specialities', 'Cuisine_Taiwanese', 'Cuisine_Hang_Zhou', 'Cuisine_Indian_Vegetarian', 'Cuisine_Vietnamese_Contemporary', 'Cuisine_Teppanyaki', 'Cuisine_Vietnamese', 'Cuisine_Croatian', 'Cuisine_Teochew', 'Cuisine_Norwegian', 'Cuisine_Danish', 'Cuisine_Zhejiang', 'Cuisine_Fugu__Pufferfish', 'Cuisine_Russian', 'Cuisine_North_African', 'Cuisine_Provenal', 'Cuisine_Corsican', 'Cuisine_Shun_Tak', 'Cuisine_Cantonese_Roast_Meats', 'Cuisine_Pakistani', 'Cuisine_Noodles_and_Congee', 'Cuisine_Belgian', 'Cuisine_Home_Cooking', 'Cuisine_Mandu', 'Cuisine_Ramen', 'Cuisine_Jokbal', 'Cuisine_Memilguksu', 'Cuisine_Seolleongtang', 'Cuisine_Soba', 'Cuisine_Dubu', 'Cuisine_Kalguksu', 'Cuisine_Doganitang', 'Cuisine_Sujebi', 'Cuisine_Bibimbap', 'Cuisine_Gejang', 'Cuisine_Bulgogi', 'Cuisine_Chueotang', 'Cuisine_Yukhoe', 'Cuisine_Udon', 'Cuisine_Lyonnaise', 'Cuisine_Persian', 'Cuisine_South_East_Asian', 'Cuisine_South_Indian', 'Cuisine_Sri_Lankan', 'Cuisine_Scottish', 'Cuisine_Creole', 'Cuisine_Cajun', 'Cuisine_South_African', 'Cuisine_Izakaya', 'Cuisine_Regional_European', 'Cuisine_Pizza', 'Cuisine_Moroccan', 'Cuisine_Central_Asian', 'Cuisine_Isan', 'Cuisine_TexMex', 'Cuisine_Burmese', 'Cuisine_Chicken_Specialities', 'Cuisine_Deli', 'Cuisine_Cambodian', 'Cuisine_Polish', 'Cuisine_Roman', 'Cuisine_Tibetan', 'Cuisine_Czech', 'Cuisine_Gastropub', 'Cuisine_Lao', 'Cuisine_Bakery', 'Cuisine_Caribbean', 'Cuisine_Afghan', 'Cuisine_English', 'Cuisine_Congee', 'Cuisine_Small_eats', 'Cuisine_Yunnanese', 'Cuisine_ThaiChinese', 'Cuisine_Northern_Thai', 'Cuisine_Rice_Dishes', 'Cuisine_Pork', 'Cuisine_Hakkanese', 'Cuisine_Egyptian', 'Cuisine_Jamaican', 'Cuisine_Cuisine_from_Valtellina', 'Cuisine_Cuisine_from_Basilicata', 'Cuisine_Mantuan', 'Cuisine_Friulian', 'Cuisine_South_Tyrolean', 'Cuisine_Armenian', 'Cuisine_Venezuelan', 'Cuisine_Tonkatsu', 'Cuisine_Yoshoku', 'Cuisine_Onigiri', 'Cuisine_Hubei', 'Cuisine_Hotpot', 'Cuisine_Indonesian', 'Cuisine_Balinese', 'Cuisine_Milanese', 'Cuisine_Thai_and_Vietnamese', 'Cuisine_Ethiopian', 'Cuisine_Balkan', 'Cuisine_Xibei', 'Cuisine_Smrrebrd', 'Cuisine_Kushiage', 'Cuisine_Cuban', 'Cuisine_Nepali', 'Cuisine_Oden', 'Cuisine_Okonomiyaki', 'Cuisine_Obanzai', 'Cuisine_Bavarian', 'Cuisine_Savoyard', 'Cuisine_Breton', 'Cuisine_Chiu_Chow', 'Cuisine_Macanese', 'Cuisine_Singaporean_and_Malaysian', 'Cuisine_Xinjiang', 'Cuisine_Cuisine_from_South_West_France', 'Cuisine_Argentinian', 'Cuisine_Australian_Contemporary', 'Cuisine_Meats_and_Seafood', 'Cuisine_Japanese_Steakhouse', 'Cuisine_Oyster_Specialities', 'Cuisine_Eastern_European', 'Cuisine_Shabushabu', 'Cuisine_Lamb_Specialities', 'Cuisine_Hui_Cuisine', 'Cuisine_Fish_and_Chips', 'Cuisine_Shellfish_Specialities', 'Cuisine_Cheese', 'Cuisine_Fondue_and_Raclette', 'Cuisine_Sukiyaki', 'Cuisine_Shaanxi', 'Cuisine_Hunanese_and_Sichuan', 'Cuisine_Puerto_Rican', 'Cuisine_Curry', 'Cuisine_Hainanese', 'Cuisine_Finnish', 'Cuisine_406_Kameyacho', 'Cuisine_Nakagyoku', 'Cuisine_Kyoto', 'Cuisine_6040941', 'Cuisine_Japan', 'Cuisine_Swabian', 'Cuisine_Cuisine_from_FrancheComt', 'Cuisine_Burgundian', 'Cuisine_Crpe', 'Cuisine_Flemish', 'RestaurantsDelivery', 'OutdoorSeating', 'BusinessAcceptsCreditCards', 'BusinessParking_garage', 'BusinessParking_street', 'BusinessParking_validated', 'BusinessParking_lot', 'BusinessParking_valet', 'BikeParking', 'RestaurantsTakeOut', 'WiFi', 'Alcohol', 'Caters', 'WheelchairAccessible', 'GoodForKids', 'RestaurantsAttire', 'RestaurantsReservations', 'DogsAllowed', 'RestaurantsTableService', 'RestaurantsGoodForGroups', 'HasTV', 'HappyHour', 'Ambience_touristy', 'Ambience_hipster', 'Ambience_romantic', 'Ambience_divey', 'Ambience_intimate', 'Ambience_trendy', 'Ambience_upscale', 'Ambience_classy', 'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight', 'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch', 'GoodForMeal_breakfast', 'NoiseLevel']\n",
            "Columns for database: ['name', 'address', 'stars', 'latitude', 'longitude', 'is_michelin', 'business_id', 'RestaurantsPriceRange2']\n",
            "  business_id   longitude   latitude     stars  Air_conditioning  \\\n",
            "0           0  127.044260  37.525350  4.255147                 1   \n",
            "1           1   -2.953868  54.201771  4.510165                 1   \n",
            "2           2   -0.152575  51.507338  4.651957                 1   \n",
            "3           3   -0.149290  51.510188  4.291892                 1   \n",
            "4           4   -0.162177  51.485438  4.897332                 1   \n",
            "\n",
            "   Cuisine_Korean  Cuisine_Korean_Contemporary  RestaurantsPriceRange2  \\\n",
            "0               1                            1                       4   \n",
            "1               0                            0                       4   \n",
            "2               0                            0                       4   \n",
            "3               0                            0                       4   \n",
            "4               0                            0                       4   \n",
            "\n",
            "   Cuisine_Creative_British  Cuisine_French  ...  Ambience_upscale  \\\n",
            "0                         0               0  ...                 0   \n",
            "1                         1               0  ...                 0   \n",
            "2                         0               1  ...                 0   \n",
            "3                         0               0  ...                 0   \n",
            "4                         0               1  ...                 0   \n",
            "\n",
            "   Ambience_classy  Ambience_casual  GoodForMeal_dessert  \\\n",
            "0                0                0                    0   \n",
            "1                0                0                    0   \n",
            "2                0                0                    0   \n",
            "3                0                0                    0   \n",
            "4                0                0                    0   \n",
            "\n",
            "   GoodForMeal_latenight  GoodForMeal_lunch  GoodForMeal_dinner  \\\n",
            "0                      0                  0                   0   \n",
            "1                      0                  0                   0   \n",
            "2                      0                  0                   0   \n",
            "3                      0                  0                   0   \n",
            "4                      0                  0                   0   \n",
            "\n",
            "   GoodForMeal_brunch  GoodForMeal_breakfast  NoiseLevel  \n",
            "0                   0                      0           0  \n",
            "1                   0                      0           0  \n",
            "2                   0                      0           0  \n",
            "3                   0                      0           0  \n",
            "4                   0                      0           0  \n",
            "\n",
            "[5 rows x 325 columns]\n"
          ]
        }
      ],
      "source": [
        "# save restaurants to json for db import and csv for model training\n",
        "restaurant_df_model_training = combined_df.copy().drop(columns=['name', 'address', 'is_michelin'])\n",
        "picture_df.to_csv('../data/cleaned_photos.csv', index=False)\n",
        "\n",
        "# keep name, address, stars, latitude, longitude, is_michelin, business_id, RestaurantsPriceRange2\n",
        "# Select important columns for database\n",
        "columns_to_keep = ['name', 'address', 'stars', 'latitude', 'longitude', 'is_michelin', 'business_id']\n",
        "print(combined_df[\"RestaurantsPriceRange2\"].unique())\n",
        "# Find the RestaurantsPriceRange2 column (it might be extracted from attributes)\n",
        "# Ensure the price column name is cleaned if necessary\n",
        "price_col_name = 'RestaurantsPriceRange2'\n",
        "if price_col_name not in combined_df.columns:\n",
        "    # Attempt to find a similarly named column if cleaning changed it\n",
        "    potential_price_cols = [col for col in combined_df.columns if 'RestaurantsPriceRange' in col]\n",
        "    if potential_price_cols:\n",
        "        price_col_name = potential_price_cols[0]\n",
        "    else:\n",
        "        print(\"Warning: RestaurantsPriceRange2 column not found. Price will not be included in DB export.\")\n",
        "        price_col_name = None\n",
        "\n",
        "if price_col_name and price_col_name in combined_df.columns:\n",
        "    # convert price_col to string for JSON export if it's numeric\n",
        "    if pd.api.types.is_numeric_dtype(combined_df[price_col_name]):\n",
        "         combined_df[price_col_name] = combined_df[price_col_name].astype(str)\n",
        "    columns_to_keep.append(price_col_name)\n",
        "else:\n",
        "    price_col_name = None # Ensure it's None if not added\n",
        "\n",
        "# Create database version with selected columns\n",
        "restaurant_df_database = combined_df[columns_to_keep].copy()\n",
        "picture_df.to_json('../data/cleaned_photos.json', orient='records', lines=True)\n",
        "\n",
        "print(\"Columns for model training:\", restaurant_df_model_training.columns.to_list())\n",
        "print(\"Columns for database:\", restaurant_df_database.columns.to_list())\n",
        "print(restaurant_df_model_training.head())\n",
        "restaurant_df_database.to_json('../data/cleaned_restaurants.json', orient='records', lines=True)\n",
        "restaurant_df_model_training.to_pickle('../data/cleaned_restaurants.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 1 3 2 0]\n"
          ]
        }
      ],
      "source": [
        "print(restaurant_df_model_training['RestaurantsPriceRange2'].unique())"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
