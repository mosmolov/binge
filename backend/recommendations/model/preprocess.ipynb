{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_datalist = []\n",
    "with open('../data/photos.json', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        photo_datalist.append(data)\n",
    "\n",
    "restaurant_datalist = []\n",
    "with open('../data/yelp_academic_dataset_business.json', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        restaurant_datalist.append(data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                             {'ByAppointmentOnly': 'True'}\n",
      "1                    {'BusinessAcceptsCreditCards': 'True'}\n",
      "2         {'BikeParking': 'True', 'BusinessAcceptsCredit...\n",
      "3         {'RestaurantsDelivery': 'False', 'OutdoorSeati...\n",
      "4         {'BusinessAcceptsCreditCards': 'True', 'Wheelc...\n",
      "                                ...                        \n",
      "150341    {'ByAppointmentOnly': 'False', 'RestaurantsPri...\n",
      "150342    {'BusinessAcceptsCreditCards': 'True', 'Restau...\n",
      "150343    {'RestaurantsPriceRange2': '1', 'BusinessAccep...\n",
      "150344    {'BusinessParking': '{'garage': False, 'street...\n",
      "150345    {'WheelchairAccessible': 'True', 'BusinessAcce...\n",
      "Name: attributes, Length: 150346, dtype: object\n",
      "Index(['Name', 'Address', 'Location', 'Price', 'Cuisine', 'Longitude',\n",
      "       'Latitude', 'PhoneNumber', 'Url', 'WebsiteUrl', 'Award', 'GreenStar',\n",
      "       'FacilitiesAndServices', 'Description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# clean photos\n",
    "# create dataframe\n",
    "picture_df = pd.DataFrame(photo_datalist)\n",
    "restaurant_df = pd.DataFrame(restaurant_datalist)\n",
    "michelin_df = pd.read_csv('../data/michelin.csv')\n",
    "print(restaurant_df['attributes'])\n",
    "print(michelin_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean michelin\n",
    "michelin_df = michelin_df.drop(columns=['PhoneNumber', 'Url', 'WebsiteUrl', 'Award', 'GreenStar', 'Description', 'Location'])\n",
    "# encode prices based on number of characters\n",
    "michelin_df[\"Price\"] = michelin_df[\"Price\"].apply(lambda x: str(len(str(x))))\n",
    "facilities_and_services = michelin_df[\"FacilitiesAndServices\"].apply(lambda x: x.split(\",\") if isinstance(x, str) else [])\n",
    "michelin_df[\"attributes\"] = facilities_and_services.apply(lambda x: {item.strip(): True for item in x})\n",
    "# Process cuisine properly - use apply with a function that has access to row index\n",
    "for idx, row in michelin_df.iterrows():\n",
    "    cuisine_list = row[\"Cuisine\"].split(\",\") if isinstance(row[\"Cuisine\"], str) else []\n",
    "    cuisine_clean = [c.strip() for c in cuisine_list]\n",
    "    price = row[\"Price\"]\n",
    "    # Update attributes for this specific row\n",
    "    michelin_df.at[idx, \"attributes\"] = {**michelin_df.at[idx, \"attributes\"], \n",
    "                                         \"Cuisine\": cuisine_clean,\n",
    "                                         \"RestaurantsPriceRange2\": price.strip()}\n",
    "michelin_df['is_michelin'] = True\n",
    "restaurant_df['is_michelin'] = False\n",
    "# generate random high ratings for michelin restaurants\n",
    "michelin_df['stars'] = np.random.uniform(4, 5, michelin_df.shape[0])\n",
    "# generate business_ids for michelin\n",
    "michelin_df['business_id'] = np.arange(len(michelin_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align michelin_df and restaurant_df\n",
    "restaurant_df = restaurant_df.drop(columns=['hours', 'review_count', 'is_open'])\n",
    "michelin_df = michelin_df.drop(columns=['FacilitiesAndServices', 'Cuisine', 'Price'])\n",
    "michelin_df = michelin_df.rename(columns={\n",
    "    \"Name\": \"name\",\n",
    "    \"Address\": \"address\",\n",
    "    \"Longitude\": \"longitude\",\n",
    "    \"Latitude\": \"latitude\",\n",
    "})\n",
    "# combine address, city, state, postal_code fields into one column\n",
    "restaurant_df[\"address\"] = restaurant_df[\"address\"] + \", \" + restaurant_df[\"city\"] + \", \" + restaurant_df[\"state\"] + \" \" + restaurant_df[\"postal_code\"]\n",
    "restaurant_df = restaurant_df.drop(columns=['city', 'state', 'postal_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of food establishments: 51036\n",
      "Number of photos for food establishments: 81941\n",
      "\n",
      "Sample categories in filtered dataset:\n",
      "['Restaurants, Food, Bubble Tea, Coffee & Tea, Bakeries'\n",
      " 'Brewpubs, Breweries, Food'\n",
      " 'Burgers, Fast Food, Sandwiches, Food, Ice Cream & Frozen Yogurt, Restaurants'\n",
      " ... 'Restaurants, Sandwiches, Convenience Stores, Coffee & Tea, Food'\n",
      " 'Cafes, Juice Bars & Smoothies, Coffee & Tea, Restaurants, Food'\n",
      " 'Specialty Food, Food, Coffee & Tea, Coffee Roasteries']\n",
      "Index(['business_id', 'name', 'address', 'latitude', 'longitude', 'stars',\n",
      "       'attributes', 'categories', 'is_michelin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "non_food_terms = '|'.join(['Salon', 'Barber', 'Gym', 'Spa', 'Theater', 'Nightlife', 'Beauty', 'Barbershop', \"Active Life\",\n",
    "    \"Automotive\",\n",
    "    \"Beauty & Spas\",\n",
    "    \"Home Services\",\n",
    "    \"Health & Medical\",\n",
    "    \"Hotels & Travel\",\n",
    "    \"Local Services\",\n",
    "    \"Professional Services\",\n",
    "    \"Public Services & Government\",\n",
    "    \"Real Estate\",\n",
    "    \"Religious Organizations\",\n",
    "    \"Shopping & Retail\",\n",
    "    \"Transportation\",\n",
    "    \"Arts & Entertainment\",\n",
    "    \"Event Planning & Services\",\n",
    "    \"Education\",\n",
    "    \"Financial Services\",\n",
    "    \"Nightlife\",\n",
    "    \"Pets & Animal Services\",\n",
    "    \"Sports & Recreation\",\n",
    "    \"Miscellaneous Services\",\n",
    "    \"Shopping\", \"Women's Clothing\", \"Fashion\"\n",
    "])\n",
    "\n",
    "# Filter out non-food related businesses\n",
    "restaurant_df = restaurant_df[~restaurant_df['categories'].str.contains(non_food_terms, case=False, na=False)]\n",
    "picture_df = picture_df[picture_df['label'] != 'inside']\n",
    "picture_df = picture_df[picture_df['label'] != 'outside']\n",
    "picture_df = picture_df[picture_df['label'] != 'menu']\n",
    "# Keep only photos that belong to the filtered restaurants\n",
    "picture_df = picture_df[picture_df['business_id'].isin(restaurant_df['business_id'])]\n",
    "\n",
    "# Print statistics\n",
    "print(\"Number of food establishments:\", len(restaurant_df))\n",
    "print(\"Number of photos for food establishments:\", len(picture_df))\n",
    "print(\"\\nSample categories in filtered dataset:\")\n",
    "print(restaurant_df['categories'].unique())\n",
    "print(restaurant_df.columns)\n",
    "\n",
    "restaurant_df = restaurant_df.drop(columns=[\"categories\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Terrace': True, 'Cuisine': ['Regional Cuisine', 'Seasonal Cuisine'], 'RestaurantsPriceRange2': '3'}]\n",
      "['business_id', 'name', 'address', 'longitude', 'latitude', 'attributes', 'is_michelin', 'stars']\n",
      "[{'RestaurantsPriceRange2': '1', 'RestaurantsDelivery': 'True', 'RestaurantsTakeOut': 'True', 'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}\", 'BusinessAcceptsCreditCards': 'True'}, {'Air conditioning': True, 'Counter dining': True, 'Wheelchair access': True, 'Cuisine': ['Contemporary', 'Italian'], 'RestaurantsPriceRange2': '4'}, {'Air conditioning': True, 'Car park': True, 'Cash only': True, 'Cuisine': ['Vietnamese', 'Noodles'], 'RestaurantsPriceRange2': '1'}, {'RestaurantsGoodForGroups': 'True', 'WiFi': \"u'free'\", 'Ambience': \"{'romantic': False, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': False, 'trendy': False, 'upscale': False, 'casual': False}\", 'RestaurantsTakeOut': 'False', 'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': True}\", 'RestaurantsDelivery': 'False', 'RestaurantsReservations': 'False', 'RestaurantsPriceRange2': '2', 'BusinessAcceptsBitcoin': 'False', 'GoodForKids': 'False', 'BikeParking': 'False', 'WheelchairAccessible': 'True', 'BusinessAcceptsCreditCards': 'True', 'Alcohol': \"u'full_bar'\", 'RestaurantsAttire': \"u'casual'\", 'Caters': 'False', 'OutdoorSeating': 'False', 'HasTV': 'True', 'DogsAllowed': 'False', 'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': False, 'dinner': False, 'brunch': False, 'breakfast': False}\", 'RestaurantsTableService': 'True'}, {'Air conditioning': True, 'Great view': True, 'Terrace': True, 'Wheelchair access': True, 'Cuisine': ['Traditional Cuisine'], 'RestaurantsPriceRange2': '2'}, {'Air conditioning': True, 'Counter dining': True, 'Cuisine': ['Seafood'], 'RestaurantsPriceRange2': '2'}, None, {'RestaurantsDelivery': 'True', 'RestaurantsReservations': 'False', 'BusinessAcceptsCreditCards': 'True', 'RestaurantsTakeOut': 'True', 'Alcohol': \"'none'\", 'WiFi': \"u'free'\", 'GoodForKids': 'True', 'RestaurantsAttire': \"'casual'\", 'RestaurantsGoodForGroups': 'True', 'OutdoorSeating': 'True', 'RestaurantsPriceRange2': '1', 'BusinessParking': \"{'garage': False, 'street': True, 'validated': False, 'lot': False, 'valet': False}\"}, {'Air conditioning': True, 'Terrace': True, 'Wheelchair access': True, 'Cuisine': ['Contemporary'], 'RestaurantsPriceRange2': '3'}, None]\n"
     ]
    }
   ],
   "source": [
    "# union michelin_df and restaurant_df based on business_id as index\n",
    "michelin_df = michelin_df.set_index('business_id')\n",
    "print(michelin_df[\"attributes\"].sample(1).to_list())\n",
    "restaurant_df = restaurant_df.set_index('business_id')\n",
    "combined_df = pd.concat([michelin_df, restaurant_df], axis=0)\n",
    "combined_df = combined_df.reset_index()\n",
    "print(combined_df.columns.to_list())\n",
    "print(combined_df[\"attributes\"].sample(10).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def extract_and_encode_attributes(df):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe with a column 'attributes' that contains nested JSON-like data.\n",
    "    It flattens the nested structure, encodes list values into dummy variables, and merges the encoded\n",
    "    features back into the original dataframe.\n",
    "\n",
    "    Parameters:\n",
    "      df (pd.DataFrame): Input dataframe containing at least the \"attributes\" column.\n",
    "    \n",
    "    Returns:\n",
    "      pd.DataFrame: A new dataframe with encoded attributes features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def flatten_dict(d, parent_key='', sep='_'):\n",
    "        \"\"\"\n",
    "        Recursively flattens a nested dictionary, joining keys with the specified separator.\n",
    "        \n",
    "        Parameters:\n",
    "          d (dict): The dictionary to flatten.\n",
    "          parent_key (str): The string to prepend to keys (used for recursion).\n",
    "          sep (str): Separator between concatenated keys.\n",
    "          \n",
    "        Returns:\n",
    "          dict: The flattened dictionary.\n",
    "        \"\"\"\n",
    "        items = {}\n",
    "        for k, v in d.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "            # If the value is a dictionary, flatten it recursively.\n",
    "            if isinstance(v, dict):\n",
    "                items.update(flatten_dict(v, new_key, sep=sep))\n",
    "            # If the value is a string that looks like a dictionary, try to convert it.\n",
    "            elif isinstance(v, str) and v.strip().startswith(\"{\") and v.strip().endswith(\"}\"):\n",
    "                try:\n",
    "                    nested = ast.literal_eval(v)\n",
    "                    if isinstance(nested, dict):\n",
    "                        items.update(flatten_dict(nested, new_key, sep=sep))\n",
    "                    else:\n",
    "                        items[new_key] = v\n",
    "                except Exception:\n",
    "                    items[new_key] = v\n",
    "            else:\n",
    "                items[new_key] = v\n",
    "        return items\n",
    "\n",
    "    def process_attributes(attr):\n",
    "        \"\"\"\n",
    "        Processes the attribute entry from a single row.\n",
    "        It converts string representations of dictionaries into a dictionary,\n",
    "        and then flattens the structure.\n",
    "        \n",
    "        Parameters:\n",
    "          attr: The attribute data (could be a dictionary, string, or None).\n",
    "          \n",
    "        Returns:\n",
    "          dict: A flattened dictionary of attributes.\n",
    "        \"\"\"\n",
    "        if attr is None:\n",
    "            return {}\n",
    "        if isinstance(attr, str):\n",
    "            try:\n",
    "                attr = ast.literal_eval(attr)\n",
    "            except Exception:\n",
    "                return {}\n",
    "        if isinstance(attr, dict):\n",
    "            return flatten_dict(attr)\n",
    "        return {}\n",
    "\n",
    "    # Apply processing to every row's 'attributes' column.\n",
    "    flat_attributes = df['attributes'].apply(process_attributes)\n",
    "    \n",
    "    # Convert the list of dictionaries into a DataFrame (one row per original row).\n",
    "    attr_df = pd.json_normalize(flat_attributes)\n",
    "    \n",
    "    # Check and encode any list values as one-hot encoded columns.\n",
    "    for col in attr_df.columns:\n",
    "        # If any non-null entry is a list...\n",
    "        if attr_df[col].dropna().apply(lambda x: isinstance(x, list)).any():\n",
    "            # Explode the list into separate rows, get dummies, and then aggregate back per row.\n",
    "            dummies = attr_df[col].explode().str.get_dummies().groupby(level=0).max()\n",
    "            # Rename columns with a prefix for clarity.\n",
    "            dummies = dummies.add_prefix(f\"{col}_\")\n",
    "            # Remove the original list column and join the new dummy columns.\n",
    "            attr_df = attr_df.drop(columns=[col]).join(dummies)\n",
    "    \n",
    "    # Optionally, convert string booleans to actual booleans.\n",
    "    bool_map = {'True': True, 'False': False}\n",
    "    for col in attr_df.columns:\n",
    "        if attr_df[col].dtype == object:\n",
    "            attr_df[col] = attr_df[col].map(bool_map).fillna(attr_df[col])\n",
    "    \n",
    "    # Fill missing values. Adjust the fill strategy depending on your model.\n",
    "    attr_df = attr_df.fillna(0)\n",
    "    \n",
    "    # Merge the encoded features back with the original dataframe.\n",
    "    df_encoded = pd.concat([df.reset_index(drop=True), attr_df.reset_index(drop=True)], axis=1)\n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract attributes and create recommendation features\n",
    "combined_df = extract_and_encode_attributes(combined_df)\n",
    "combined_df = combined_df.drop(columns=['attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id           object\n",
      "name                  object\n",
      "address               object\n",
      "longitude            float64\n",
      "latitude             float64\n",
      "                      ...   \n",
      "Cuisine_Yakitori       int64\n",
      "Cuisine_Yoshoku        int64\n",
      "Cuisine_Yukhoe         int64\n",
      "Cuisine_Yunnanese      int64\n",
      "Cuisine_Zhejiang       int64\n",
      "Length: 384, dtype: object\n",
      "(68782, 384)\n",
      "['business_id', 'name', 'address', 'longitude', 'latitude', 'is_michelin', 'stars', 'Air conditioning', 'Interesting wine list', 'Valet parking', 'Wheelchair access', 'RestaurantsPriceRange2', 'Garden or park', 'Restaurant offering vegetarian menus', 'Car park', 'Great view', 'Terrace', 'Counter dining', 'Notable sake list', 'Shoes must be removed', 'Cash only', 'Brunch', 'Credit cards not accepted', 'Bring your own bottle', 'Cash only - lunch', 'Foreign credit cards not accepted', 'Booking essential', 'Booking essential - dinner', 'RestaurantsDelivery', 'OutdoorSeating', 'BusinessAcceptsCreditCards', 'BusinessParking_garage', 'BusinessParking_street', 'BusinessParking_validated', 'BusinessParking_lot', 'BusinessParking_valet', 'BikeParking', 'RestaurantsTakeOut', 'ByAppointmentOnly', 'WiFi', 'Alcohol', 'Caters', 'WheelchairAccessible', 'GoodForKids', 'BusinessParking', 'RestaurantsAttire', 'RestaurantsReservations', 'Ambience', 'CoatCheck', 'DogsAllowed', 'RestaurantsTableService', 'RestaurantsGoodForGroups', 'HasTV', 'HappyHour', 'DriveThru', 'Ambience_touristy', 'Ambience_hipster', 'Ambience_romantic', 'Ambience_divey', 'Ambience_intimate', 'Ambience_trendy', 'Ambience_upscale', 'Ambience_classy', 'Ambience_casual', 'GoodForMeal_dessert', 'GoodForMeal_latenight', 'GoodForMeal_lunch', 'GoodForMeal_dinner', 'GoodForMeal_brunch', 'GoodForMeal_breakfast', 'NoiseLevel', 'BusinessAcceptsBitcoin', 'BYOB', 'Corkage', 'BYOBCorkage', 'GoodForMeal', 'Smoking', 'RestaurantsCounterService', 'BestNights_monday', 'BestNights_tuesday', 'BestNights_friday', 'BestNights_wednesday', 'BestNights_thursday', 'BestNights_sunday', 'BestNights_saturday', 'Music_dj', 'Music_background_music', 'Music_jukebox', 'Music_live', 'Music_video', 'Music_karaoke', 'GoodForDancing', 'Open24Hours', 'AgesAllowed', 'DietaryRestrictions_dairy-free', 'DietaryRestrictions_gluten-free', 'DietaryRestrictions_vegan', 'DietaryRestrictions_kosher', 'DietaryRestrictions_halal', 'DietaryRestrictions_soy-free', 'DietaryRestrictions_vegetarian', 'Music_no_music', 'DietaryRestrictions', 'AcceptsInsurance', 'Cuisine_406 Kameyacho', 'Cuisine_604-0941', 'Cuisine_Afghan', 'Cuisine_African', 'Cuisine_Alpine', 'Cuisine_Alsatian', 'Cuisine_American', 'Cuisine_American Contemporary', 'Cuisine_Andalusian', 'Cuisine_Apulian', 'Cuisine_Argentinian', 'Cuisine_Armenian', 'Cuisine_Asian', 'Cuisine_Asian Contemporary', 'Cuisine_Asian Influences', 'Cuisine_Asian and Western', 'Cuisine_Asturian', 'Cuisine_Australian Contemporary', 'Cuisine_Austrian', 'Cuisine_Bakery', 'Cuisine_Balinese', 'Cuisine_Balkan', 'Cuisine_Barbecue', 'Cuisine_Basque', 'Cuisine_Bavarian', 'Cuisine_Beef', 'Cuisine_Beijing Cuisine', 'Cuisine_Belgian', 'Cuisine_Bibimbap', 'Cuisine_Brazilian', 'Cuisine_Breton', 'Cuisine_British Contemporary', 'Cuisine_Bulgogi', 'Cuisine_Burgundian', 'Cuisine_Burmese', 'Cuisine_Cajun', 'Cuisine_Calabrian', 'Cuisine_Californian', 'Cuisine_Cambodian', 'Cuisine_Campanian', 'Cuisine_Cantonese', 'Cuisine_Cantonese Roast Meats', 'Cuisine_Caribbean', 'Cuisine_Castilian', 'Cuisine_Catalan', 'Cuisine_Central Asian', 'Cuisine_Chao Zhou', 'Cuisine_Cheese', 'Cuisine_Chicken Specialities', 'Cuisine_Chinese', 'Cuisine_Chinese Contemporary', 'Cuisine_Chiu Chow', 'Cuisine_Chueotang', 'Cuisine_Classic Cuisine', 'Cuisine_Classic French', 'Cuisine_Colombian', 'Cuisine_Congee', 'Cuisine_Contemporary', 'Cuisine_Corsican', 'Cuisine_Country cooking', 'Cuisine_Crab Specialities', 'Cuisine_Creative', 'Cuisine_Creative British', 'Cuisine_Creative French', 'Cuisine_Creole', 'Cuisine_Croatian', 'Cuisine_Crêpe', 'Cuisine_Cuban', 'Cuisine_Cuisine from Abruzzo', 'Cuisine_Cuisine from Basilicata', 'Cuisine_Cuisine from Franche-Comté', 'Cuisine_Cuisine from Lazio', 'Cuisine_Cuisine from Romagna', 'Cuisine_Cuisine from South West France', 'Cuisine_Cuisine from Valtellina', 'Cuisine_Cuisine from the Aosta Valley', 'Cuisine_Cuisine from the Marches', 'Cuisine_Curry', 'Cuisine_Czech', 'Cuisine_Danish', 'Cuisine_Deli', 'Cuisine_Dim Sum', 'Cuisine_Doganitang', 'Cuisine_Dongbei', 'Cuisine_Dubu', 'Cuisine_Duck Specialities', 'Cuisine_Dumplings', 'Cuisine_Dwaeji-gukbap', 'Cuisine_Eastern European', 'Cuisine_Egyptian', 'Cuisine_Emilian', 'Cuisine_Emirati Cuisine', 'Cuisine_English', 'Cuisine_Ethiopian', 'Cuisine_European', 'Cuisine_European Contemporary', 'Cuisine_Farm to table', 'Cuisine_Filipino', 'Cuisine_Finnish', 'Cuisine_Fish and Chips', 'Cuisine_Flemish', 'Cuisine_Fondue and Raclette', 'Cuisine_French', 'Cuisine_French Contemporary', 'Cuisine_Friulian', 'Cuisine_Fugu / Pufferfish', 'Cuisine_Fujian', 'Cuisine_Fusion', 'Cuisine_Galician', 'Cuisine_Gastropub', 'Cuisine_Gejang', 'Cuisine_German', 'Cuisine_Gomtang', 'Cuisine_Greek', 'Cuisine_Grills', 'Cuisine_Hainanese', 'Cuisine_Hakkanese', 'Cuisine_Hang Zhou', 'Cuisine_Home Cooking', 'Cuisine_Hotpot', 'Cuisine_Huaiyang', 'Cuisine_Hubei', 'Cuisine_Hui Cuisine', 'Cuisine_Hunanese', 'Cuisine_Hunanese and Sichuan', 'Cuisine_Hungarian', 'Cuisine_Indian', 'Cuisine_Indian Vegetarian', 'Cuisine_Indonesian', 'Cuisine_Innovative', 'Cuisine_International', 'Cuisine_Irish', 'Cuisine_Isan', 'Cuisine_Israeli', 'Cuisine_Italian', 'Cuisine_Italian Contemporary', 'Cuisine_Italian and Japanese', 'Cuisine_Italian-American', 'Cuisine_Izakaya', 'Cuisine_Jamaican', 'Cuisine_Japan', 'Cuisine_Japanese', 'Cuisine_Japanese Contemporary', 'Cuisine_Japanese Steakhouse', 'Cuisine_Jiangzhe', 'Cuisine_Jokbal', 'Cuisine_Kalguksu', 'Cuisine_Korean', 'Cuisine_Korean Contemporary', 'Cuisine_Kushiage', 'Cuisine_Kyoto', 'Cuisine_Lamb Specialities', 'Cuisine_Lao', 'Cuisine_Latin American', 'Cuisine_Lebanese', 'Cuisine_Ligurian', 'Cuisine_Lombardian', 'Cuisine_Lyonnaise', 'Cuisine_Macanese', 'Cuisine_Malaysian', 'Cuisine_Mandu', 'Cuisine_Mantuan', 'Cuisine_Meats and Grills', 'Cuisine_Meats and Seafood', 'Cuisine_Mediterranean Cuisine', 'Cuisine_Memil-guksu', 'Cuisine_Mexican', 'Cuisine_Middle Eastern', 'Cuisine_Milanese', 'Cuisine_Modern British', 'Cuisine_Modern Cuisine', 'Cuisine_Modern French', 'Cuisine_Moroccan', 'Cuisine_Naengmyeon', 'Cuisine_Nakagyo-ku', 'Cuisine_Nepali', 'Cuisine_Ningbo', 'Cuisine_Noodles', 'Cuisine_Noodles and Congee', 'Cuisine_North African', 'Cuisine_North American', 'Cuisine_Northern Thai', 'Cuisine_Norwegian', 'Cuisine_Obanzai', 'Cuisine_Oden', 'Cuisine_Okonomiyaki', 'Cuisine_Onigiri', 'Cuisine_Organic', 'Cuisine_Oyster Specialities', 'Cuisine_Pakistani', 'Cuisine_Peranakan', 'Cuisine_Persian', 'Cuisine_Peruvian', 'Cuisine_Piedmontese', 'Cuisine_Pizza', 'Cuisine_Polish', 'Cuisine_Pork', 'Cuisine_Portuguese', 'Cuisine_Provençal', 'Cuisine_Puerto Rican', 'Cuisine_Ramen', 'Cuisine_Regional Cuisine', 'Cuisine_Regional European', 'Cuisine_Rice Dishes', 'Cuisine_Roman', 'Cuisine_Russian', 'Cuisine_Sardinian', 'Cuisine_Savoyard', 'Cuisine_Scandinavian', 'Cuisine_Scottish', 'Cuisine_Seafood', 'Cuisine_Seasonal Cuisine', 'Cuisine_Seolleongtang', 'Cuisine_Shaanxi', 'Cuisine_Shabu-shabu', 'Cuisine_Shandong', 'Cuisine_Shanghainese', 'Cuisine_Sharing', 'Cuisine_Shellfish Specialities', 'Cuisine_Shojin', 'Cuisine_Shun Tak', 'Cuisine_Sichuan', 'Cuisine_Sicilian', 'Cuisine_Singaporean', 'Cuisine_Singaporean and Malaysian', 'Cuisine_Small eats', 'Cuisine_Smørrebrød', 'Cuisine_Soba', 'Cuisine_South African', 'Cuisine_South American', 'Cuisine_South East Asian', 'Cuisine_South Indian', 'Cuisine_South Tyrolean', 'Cuisine_Southern', 'Cuisine_Southern Thai', 'Cuisine_Spanish', 'Cuisine_Spanish Contemporary', 'Cuisine_Sri Lankan', 'Cuisine_Steakhouse', 'Cuisine_Street Food', 'Cuisine_Sujebi', 'Cuisine_Sukiyaki', 'Cuisine_Sushi', 'Cuisine_Swabian', 'Cuisine_Swedish', 'Cuisine_Swiss', 'Cuisine_Taiwanese', 'Cuisine_Taiwanese contemporary', 'Cuisine_Taizhou', 'Cuisine_Tempura', 'Cuisine_Teochew', 'Cuisine_Teppanyaki', 'Cuisine_Tex-Mex', 'Cuisine_Thai', 'Cuisine_Thai and Vietnamese', 'Cuisine_Thai contemporary', 'Cuisine_Thai-Chinese', 'Cuisine_Tibetan', 'Cuisine_Tonkatsu', 'Cuisine_Traditional British', 'Cuisine_Traditional Cuisine', 'Cuisine_Turkish', 'Cuisine_Tuscan', 'Cuisine_Udon', 'Cuisine_Umbrian', 'Cuisine_Unagi / Freshwater Eel', 'Cuisine_Vegan', 'Cuisine_Vegetarian', 'Cuisine_Venetian', 'Cuisine_Venezuelan', 'Cuisine_Vietnamese', 'Cuisine_Vietnamese Contemporary', 'Cuisine_World Cuisine', 'Cuisine_Xibei', 'Cuisine_Xinjiang', 'Cuisine_Yakitori', 'Cuisine_Yoshoku', 'Cuisine_Yukhoe', 'Cuisine_Yunnanese', 'Cuisine_Zhejiang']\n"
     ]
    }
   ],
   "source": [
    "# check output based on column datatypes\n",
    "print(combined_df.dtypes)\n",
    "print(combined_df.shape)\n",
    "print(combined_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "Total pictures: 81941\n",
      "Pictures with valid restaurant links: 81941\n",
      "Pictures with invalid restaurant links: 0\n",
      "\n",
      "All pictures are linked to valid restaurants!\n"
     ]
    }
   ],
   "source": [
    "# New cell for validation\n",
    "# Check if all pictures link to valid restaurants\n",
    "# get business_ids of non-michelin restaurants\n",
    "valid_business_ids = set(combined_df[~combined_df['is_michelin']]['business_id'])\n",
    "invalid_pictures = picture_df[~picture_df['business_id'].isin(valid_business_ids)]\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(f\"Total pictures: {len(picture_df)}\")\n",
    "print(f\"Pictures with valid restaurant links: {len(picture_df) - len(invalid_pictures)}\")\n",
    "print(f\"Pictures with invalid restaurant links: {len(invalid_pictures)}\")\n",
    "\n",
    "if len(invalid_pictures) > 0:\n",
    "    print(\"\\nSample of invalid picture entries:\")\n",
    "    print(invalid_pictures.head())\n",
    "else:\n",
    "    print(\"\\nAll pictures are linked to valid restaurants!\")\n",
    "\n",
    "# Optional: Remove any invalid pictures if found\n",
    "if len(invalid_pictures) > 0:\n",
    "    picture_df = picture_df[picture_df['business_id'].isin(valid_business_ids)]\n",
    "    print(f\"\\nCleaned dataset now contains {len(picture_df)} valid pictures\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/photos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m photos_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/photos\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Iterate over all files in the photos folder\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphotos_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Extract the photo ID from the filename\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     photo_id \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Check if the photo ID is not in the valid set\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/photos'"
     ]
    }
   ],
   "source": [
    "# parse photos folder and remove any photos that are not in the cleaned dataset\n",
    "import os\n",
    "\n",
    "# Create a set of valid photo IDs\n",
    "valid_photo_ids = set(picture_df['photo_id'])\n",
    "\n",
    "# Define the path to the photos folder\n",
    "photos_folder = '../data/photos'\n",
    "\n",
    "# Iterate over all files in the photos folder\n",
    "for filename in os.listdir(photos_folder):\n",
    "    # Extract the photo ID from the filename\n",
    "    photo_id = filename.split('.')[0]\n",
    "    \n",
    "    # Check if the photo ID is not in the valid set\n",
    "    if photo_id not in valid_photo_ids:\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(photos_folder, filename)\n",
    "        \n",
    "        # Remove the file\n",
    "        os.remove(file_path)\n",
    "        print(f\"Removed invalid photo: {filename}\")\n",
    "        \n",
    "# Check the number of photos in the folder\n",
    "print(f\"Remaining photos in the folder: {len(os.listdir(photos_folder))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save restaurants to json for db import and csv for model training\n",
    "restaurant_df_model_training = combined_df.copy().drop(columns=['name', 'address'])\n",
    "picture_df.to_csv('../data/cleaned_photos.csv', index=False)\n",
    "\n",
    "# keep name, address, stars, latitude, longitude, is_michelin, business_id, RestaurantsPriceRange2\n",
    "# Select important columns for database\n",
    "columns_to_keep = ['name', 'address', 'stars', 'latitude', 'longitude', 'is_michelin', 'business_id']\n",
    "\n",
    "# Find the RestaurantsPriceRange2 column (it might be extracted from attributes)\n",
    "price_col = [col for col in combined_df.columns if 'RestaurantsPriceRange2' in col]\n",
    "\n",
    "# convert price_col to string\n",
    "combined_df[price_col] = combined_df[price_col].astype(str)\n",
    "\n",
    "# Create database version with selected columns\n",
    "restaurant_df_database = combined_df[columns_to_keep + price_col].copy()\n",
    "picture_df.to_json('../data/cleaned_photos.json', orient='records', lines=True)\n",
    "\n",
    "restaurant_df_database.to_json('../data/cleaned_restaurants.json', orient='records', lines=True)\n",
    "restaurant_df_model_training.to_csv('../data/cleaned_restaurants.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
